{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ignore this.ipynb","provenance":[{"file_id":"1Acjkzzm1iK_oWWLv1efUWgi59YAJOEL8","timestamp":1611856098425},{"file_id":"15Gz0K4HH8ZDVQOgfhqrV9RAdNhIKnA16","timestamp":1604320556177},{"file_id":"1spLdFAE7dD65wmjN43teuHSEui7yxhjT","timestamp":1595339226511},{"file_id":"1Tk0AMA0poD-YwGwSdu1NYyrPUNsWxkPD","timestamp":1590142695002},{"file_id":"1e6l5b8NIQcBnM3Rmc34sZiXOwipangYY","timestamp":1590142651559},{"file_id":"1aLOO2J4BbV8SH7kaXwqUt6PJ9uVrmvH9","timestamp":1589980181817},{"file_id":"1N6mk6WSkgriPSaK9NFNtCIBPnzfsdTfI","timestamp":1584996748180},{"file_id":"1YSaoxYU6Hws1H2vwQFLd6Wp9DSpGJo-P","timestamp":1577104513613},{"file_id":"136NdAsm_5wklbqYk46_2kSjrSD20XE97","timestamp":1571739357556},{"file_id":"1bFUtApObvywutBFsJlyZwsU-HbxZpCUj","timestamp":1563483711144}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NguG3E7fNQDC"},"source":["# Подключение бибилиотек"]},{"cell_type":"code","metadata":{"id":"0hyWYiPqLdez"},"source":["from tensorflow.keras.models import Model # Импортируем модели keras: Model\n","from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, MaxPooling2D, Conv2D, BatchNormalization # Импортируем стандартные слои keras\n","from tensorflow.keras import backend as K # Импортируем модуль backend keras'а\n","from tensorflow.keras.optimizers import Adam # Импортируем оптимизатор Adam\n","from tensorflow.keras import utils # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n","import tensorflow as tf\n","from google.colab import files # Импортируем Модуль files для работы с файлами\n","import matplotlib.pyplot as plt # Импортируем модуль pyplot библиотеки matplotlib для построения графиков\n","from tensorflow.keras.preprocessing import image # Импортируем модуль image для работы с изображениями\n","import numpy as np # Импортируем библиотеку numpy\n","from sklearn.model_selection import train_test_split\n","import time\n","import random\n","import shutil\n","import os # Импортируем библиотеку os для раоты с фаловой системой\n","from PIL import Image # импортируем модель Image для работы с изображениями\n","import seaborn as sns\n","sns.set_style('darkgrid')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xP4-NkAt96gv"},"source":["from google.colab import drive # Подключаем гугл-диск\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1z0tvvy1THBj"},"source":["# Сегментация стройки"]},{"cell_type":"markdown","metadata":{"id":"oxHD9MO-sM_u"},"source":["## Загрузка картинок\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=1651"]},{"cell_type":"code","metadata":{"id":"CbNtynGfV27x"},"source":["# Глобальные параметры\n","img_width = 512 # Ширина уменьшенной картинки \n","img_height = 768 # Высота уменьшенной картинки \n","num_classes = 2 # Задаем количество классов на изображении\n","directory = '/content/drive/My Drive/segmentation/' # Указываем путь к обучающей выборке с оригинальными изображения\n","train_directory = 'Тренировочная_стройка' # Название папки с файлами обучающей выборки\n","val_directory = 'Проверочная_стройка' # Название папки с файлами проверочной выборки"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCMLlau_qpt8"},"source":["img_width *= 2\r\n","img_height *= 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QYxjEPjtVRDy"},"source":["### Оригинальные изображения\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=1778"]},{"cell_type":"code","metadata":{"id":"ZOBq9Ms3hFgR"},"source":["seg_path = directory + \"Сегментация договоров/\"\r\n","seg_path_target = directory + \"segm/\"\r\n","imgs_path = directory + \"Договора/оригинал/\"\r\n","imgs_path_target = directory + \"orig/\"\r\n","\r\n","seg_imgs = os.listdir(seg_path)\r\n","orig_imgs = os.listdir(imgs_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hs7H9z-9H_sj"},"source":["for img in seg_imgs:\r\n","  print(seg_path+img)\r\n","  shutil.copy2(src=seg_path+img,  dst=seg_path_target+img.replace(\" копия\", \"\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYWpHbN3Y-wU"},"source":["for img in orig_imgs:\r\n","  if img.split(\".\")[0] in [a.split(\".\")[0].split(\" \")[0] for a in seg_imgs]:\r\n","    print(seg_path+img)\r\n","    shutil.copy2(src=imgs_path+img,  dst=imgs_path_target+img.replace(\" копия\", \"\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2YRpTD8dNKo"},"source":["seg_imgs = os.listdir(seg_path_target)\r\n","orig_imgs = os.listdir(imgs_path_target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRDvv0-DQHwT"},"source":["train_images = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n","val_images = [] # Создаем пустой список для хранений оригинльных изображений проверочной выборки\n","\n","cur_time = time.time() # Засекаем текущее время\n","\n","for filename in sorted(os.listdir(directory + 'orig/'))[:int(len(orig_imgs)*0.9)]: # Проходим по всем файлам в каталоге по указанному пути     \n","    train_images.append(image.load_img(os.path.join(directory + 'orig/', filename),\n","                                       target_size=(img_height, img_width))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n","print ('Обучающая выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок обучающей выборки\n","print ('Количество изображений: ', len(train_images)) # Отображаем количество элементов в обучающей выборке\n","\n","cur_time = time.time() # Засекаем текущее время\n","for filename in sorted(os.listdir(directory + 'orig/'))[int(len(orig_imgs)*0.9):]: # Проходим по всем файлам в каталоге по указанному пути                  \n","    val_images.append(image.load_img(os.path.join(directory + 'orig/',filename), \n","                                     target_size=(img_height, img_width)))  # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size   \n","print ('Проверочная выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок проверочной выборки\n","print ('Количество изображений: ', len(val_images)) # Отображаем количество элементов в проверочной выборке\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_A0a9pZxQeQM"},"source":["n = 5 # Количество выводимых случайных картинок\n","fig, axs = plt.subplots(1, n, figsize=(25, 20)) #Создаем полотно из n графиков\n","for i in range(n): # Выводим в цикле n случайных изображений\n","  img = random.choice(train_images) # Выбираем случайное фото для отображения\n","  axs[i].axis('off')\n","  axs[i].imshow(img) # Отображаем фото\n","plt.show() #Показываем изображения"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77xY4Rv1VYDY"},"source":["### Сегментированные изображения\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=1875"]},{"cell_type":"code","metadata":{"id":"tyA-q3d5YOL5"},"source":["train_segments = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n","val_segments = [] # Создаем пустой список для хранений оригинльных изображений проверочной выборки\n","\n","cur_time = time.time() # Засекаем текущее время\n","for filename in sorted(os.listdir(directory + \"segm\"))[:int(len(seg_imgs)*0.9)]: # Проходим по всем файлам в каталоге по указанному пути     \n","    train_segments.append(image.load_img(os.path.join(directory + \"segm\",filename),\n","                                       target_size=(img_height, img_width))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n","print ('Обучающая выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок обучающей выборки\n","print ('Количество изображений: ', len(train_segments)) # Отображаем количество элементов в обучающем наборе сегментированных изображений\n","\n","cur_time = time.time() # Засекаем текущее время\n","# Проходим по всем файлам в каталоге по указанному пути \n","for filename in sorted(os.listdir(directory + \"segm\"))[int(len(seg_imgs)*0.9):]:\n","    # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n","    val_segments.append(image.load_img(os.path.join(directory + \"segm\",filename), \n","                                     target_size=(img_height, img_width)))  # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size   \n","print ('Проверочная выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок проверочной выборки\n","print ('Количество изображений: ', len(val_segments)) # Отображаем количество элементов в проверочном наборе сегментированных изображений"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTeP2kM9yIgH"},"source":["n = 5 # Количество выводимых случайных картинок\n","fig, axs = plt.subplots(1, n, figsize=(25, 10)) #Создаем полотно из n графиков\n","for i in range(n): # Выводим в цикле n случайных изображений\n","  img = random.choice(train_segments) # Выбираем случайное фото для отображения\n","  axs[i].axis('off')\n","  axs[i].imshow(img) # Отображаем фото\n","plt.show() #Показываем изображения"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kvdZDyqKvJXs"},"source":["## Создание выборки"]},{"cell_type":"code","metadata":{"id":"pm5SCw51gkNG"},"source":["# xTrain = np.load(\"/content/drive/My Drive/segmentation/arrays/xTrain_large.npy\")\r\n","# xVal = np.load(\"/content/drive/My Drive/segmentation/arrays/xVal_large.npy\")\r\n","\r\n","# yTrain = np.load(\"/content/drive/My Drive/segmentation/arrays/yTrain_large.npy\")\r\n","# yVal = np.load(\"/content/drive/My Drive/segmentation/arrays/yVal_large.npy\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVsUtqQ_gpi8"},"source":["for i, image in enumerate(train_images):\r\n","  image.save(directory + 'xTrain_data/' + str(i) + '.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lgu6N0JhhA9"},"source":["for i, image in enumerate(val_images):\r\n","  image.save(directory + 'xVal_data/' + str(i) + '.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JmJQRP24h36v"},"source":["# yTrainc = np.argmax(yTrain, axis = 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3XWDb-FiRUK"},"source":["# yValc = np.argmax(yVal, axis = 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nk-Dvk6Th11s"},"source":["# for i, image in enumerate(yTrainc):\r\n","#   image_processed = image.astype(np.uint8)\r\n","#   to_save = Image.fromarray(image_processed)\r\n","#   to_save.save(directory + 'yTrain_generator/' + str(i) + '.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DksBF3u4ih5C"},"source":["# for i, image in enumerate(yValc):\r\n","#   image_processed = image.astype(np.uint8)\r\n","#   to_save = Image.fromarray(image_processed)\r\n","#   to_save.save(directory + 'yVal_generator/' + str(i) + '.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbK0KhHFvebD"},"source":["# Функция преобразования пикселя сегментированного изображения в индекс (7 классов)\n","def color2index(color):\n","  index=-1\n","  if (49>=color[0]>=0)and(49>=color[1]>=0)and(49>=color[2]>=0): \n","    index=0\n","  else: \n","    index=1\n","\n","  return index  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6rcETLr9PpT"},"source":["# Функция преобразования индекса в цвет пикселя\n","def index2color(index2):\n","  index = np.argmax(index2) # Получаем индекс максимального элемента\n","  color=[]\n","  if index == 0: color = [0, 0, 0]  # пол\n","  elif index == 1: color = [255, 255, 255]  # потолок\n","\n","  return color # Возвращаем цвет пикслея"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jE1uCwYPxiix"},"source":["# Функция перевода индекса пикслея в to_categorical\n","def rgbToohe(y, num_classes): \n","  y2 = y.copy() # Создаем копию входного массива\n","  y = y.reshape(y.shape[0] * y.shape[1], 3) # Решейпим в двумерный массив\n","  yt = [] # Создаем пустой лист\n","  for i in range(len(y)): # Проходим по всем трем канала изображения\n","    yt.append(utils.to_categorical(color2index(y[i]), num_classes=num_classes)) # Переводим пиксели в индексы и преобразуем в OHE\n","  yt = np.array(yt) # Преобразуем в numpy\n","  yt = yt.reshape(y2.shape[0], y2.shape[1], num_classes) # Решейпим к исходныму размеру\n","  return yt # Возвращаем сформированный массив"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qOZdr1l9w3-5"},"source":["# Функция формирования yTrain\n","def yt_prep(data, num_classes):\n","  yTrain = [] # Создаем пустой список под карты сегметации\n","  for seg in data: # Пробегаем по всем файлам набора с сегминтированными изображениями\n","    y = image.img_to_array(seg) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n","    y = rgbToohe(y, num_classes) # Получаем OHE-представление сформированного массива\n","    yTrain.append(y) # Добавляем очередной элемент в yTrain\n","    if len(yTrain) % 100 == 0: # Каждые 100 шагов\n","      print(len(yTrain)) # Выводим количество обработанных изображений\n","  return np.array(yTrain) # Возвращаем сформированный yTrain"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtJ1tricv9uO"},"source":["xTrain = [] # Создаем пустой список под обучающую выборку\n","for img in train_images: # Проходим по всем изображениям из train_images\n","  x = np.array(img) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n","  xTrain.append(x) # Добавляем очередной элемент в xTrain\n","xTrain = np.array(xTrain) # Переводим в numpy\n","\n","xVal = [] # Создаем пустой список под проверочную выборку\n","for img in val_images: # Проходим по всем изображениям из val_images\n","  x = np.array(img) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n","  xVal.append(x) # Добавляем очередной элемент в xTrain\n","xVal = np.array(xVal) # Переводим в numpy\n","\n","print(xTrain.shape) # Размерность обучающей выборки\n","print(xVal.shape) # Размерность проверочной выборки"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4X6ro3njwh-H"},"source":["cur_time = time.time() # Засекаем текущее время\n","yTrain = yt_prep(train_segments, num_classes)  # Создаем yTrain\n","print('Время обработки: ', round(time.time() - cur_time, 2),'c') # Выводим время работы"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6XPko4NyJrm"},"source":["cur_time = time.time() # Засекаем текущее время\n","yVal = yt_prep(val_segments, num_classes) # Создаем yVal\n","print('Время обработки: ', round(time.time() - cur_time, 2),'c') # Выводим время работы"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJI6ZhJUQTBb"},"source":["xTrain = np.concatenate((xTrain, xVal))\r\n","x_train, x_val, y_train, y_val = train_test_split(xTrain, yTrain, test_size = 0.1, shuffle = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCV-hFEGHGFK"},"source":["for i, np_img in enumerate(x_train):\r\n","  real_img = Image.fromarray(np_img)\r\n","  real_img.save(f\"/content/drive/My Drive/segmentation/generator_train/input/дог{i}.jpg\")\r\n","\r\n","for i, np_img in enumerate(x_test):\r\n","  real_img = Image.fromarray(np_img)\r\n","  real_img.save(f\"/content/drive/My Drive/segmentation/generator_test/input/дог{i}.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZxU49tyMeNq"},"source":["np.save(\"/content/drive/My Drive/segmentation/arrays/xTrain_full.npy\", x_train)\r\n","np.save(\"/content/drive/My Drive/segmentation/arrays/xVal_full.npy\", x_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vh1I9lfWMj5C"},"source":["np.save(\"/content/drive/My Drive/segmentation/arrays/yTrain_full.npy\", y_train)\r\n","np.save(\"/content/drive/My Drive/segmentation/arrays/yVal_full.npy\", y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eg42wHw3aBXL"},"source":["## Модели\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=2853"]},{"cell_type":"code","metadata":{"id":"f6W-lqDtKTzB"},"source":["def fillhole(input_image):\r\n","    '''\r\n","    input gray binary image  get the filled image by floodfill method\r\n","    Note: only holes surrounded in the connected regions will be filled.\r\n","    :param input_image:\r\n","    :return:\r\n","    '''\r\n","    im_flood_fill = input_image.copy()\r\n","    h, w = input_image.shape[:2]\r\n","    mask = np.zeros((h + 2, w + 2), np.uint8)\r\n","    im_flood_fill = im_flood_fill.astype(\"uint8\")\r\n","    cv.floodFill(im_flood_fill, mask, (0, 0), 255)\r\n","    im_flood_fill_inv = cv.bitwise_not(im_flood_fill)\r\n","    img_out = input_image | im_flood_fill_inv\r\n","    return img_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVDD6PnZaMnq"},"source":["# Функция визуализации сегментированных изображений\n","def processImage(model, count = 1, n_classes = 2):\n","  indexes = np.random.randint(0, len(xVal), count) # Получаем count случайных индексов\n","  fig, axs = plt.subplots(3, count, figsize=(25, 15)) #Создаем полотно из n графиков\n","  for i,idx in enumerate(indexes): # Проходим по всем сгенерированным индексам\n","    predict = np.array(model.predict(xVal[idx].reshape(1, img_width, img_height, 3))) # Предиктим картику\n","    pr = predict[0] # Берем нулевой элемент из перидкта\n","    pr1 = [] # Пустой лист под сегментированную картинку из predicta\n","    pr2 = [] # Пустой лист под сегменитрованную картинку из yVal\n","    pr = pr.reshape(-1, n_classes) # Решейпим предикт\n","    yr = yVal[idx].reshape(-1, n_classes) # Решейпим yVal\n","    for k in range(len(pr)): # Проходим по всем уровням (количесвто классов)\n","      pr1.append(index2color(pr[k])) # Переводим индекс в писксель\n","      pr2.append(index2color(yr[k])) # Переводим индекс в писксель\n","    pr1 = np.array(pr1) # Преобразуем в numpy\n","    pr1 = pr1.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n","    pr2 = np.array(pr2) # Преобразуем в numpy\n","    pr2 = pr2.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n","    img = Image.fromarray(pr1.astype('uint8')) # Получаем картику из предикта\n","    \n","    axs[0,i].imshow(img.convert('RGBA')) # Отображаем на графике в первой линии\n","    axs[0,i].axis('off')\n","    axs[1,i].imshow(Image.fromarray(pr2.astype('uint8'))) # Отображаем на графике во второй линии сегментированное изображение из yVal\n","    axs[1,i].axis('off')\n","    axs[2,i].imshow(Image.fromarray(xVal[idx].astype('uint8'))) # Отображаем на графике в третьей линии оригинальное изображение        \n","    axs[2,i].axis('off')\n","  plt.show()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"saboeG1-lT-X"},"source":["### Линейная сегментирующая сеть\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=3222"]},{"cell_type":"code","metadata":{"id":"Iz9NJZsW6Eua"},"source":["'''\n","  Собственная функция метрики, обрабатывающая пересечение двух областей\n","'''\n","def dice_coef(y_true, y_pred):\n","    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.) # Возвращаем площадь пересечения деленную на площадь объединения двух областей"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbkr2sB28EA8"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\r\n","cb = ModelCheckpoint(\r\n","    '/content/drive/My Drive/Нейронка для Иры/weightsL/',\r\n","    monitor=\"val_dice_coef\",\r\n","    verbose=1,\r\n","    save_best_only=True,\r\n","    save_weights_only=True,\r\n","    mode=\"max\",\r\n","    save_freq=\"epoch\",\r\n","    options=None\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJEhXlIDlTgN"},"source":["'''\n","  Функция создания сети\n","    Входные параметры:\n","    - num_classes - количество классов\n","    - input_shape - размерность карты сегментации\n","'''\n","def linearSegmentationNet(\n","      num_classes = num_classes,\n","      input_shape = (img_width, img_height, 3)\n","      ):\n","    img_input = Input(input_shape)                                          # Создаем входной слой с размерностью input_shape\n","    x = Conv2D(128, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                             # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                               # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                             # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                               # Добавляем слой Activation\n","\n","    x = Conv2D(num_classes,(3, 3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","    model = Model(img_input, x)                                             # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","    # Компилируем модель\n","    model.compile(optimizer=Adam(lr=1e-4),\n","                  loss='categorical_crossentropy',\n","                  metrics=[dice_coef])\n","    return model # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDQZK3xdjxo5"},"source":["modelL = linearSegmentationNet(num_classes, (img_width, img_height, 3)) # Создаем моель linearSegmentationNet\n","modelL.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7AQ2g-yljo-"},"source":["modelL = linearSegmentationNet(num_classes, (img_width, img_height, 3)) # Создаем моель linearSegmentationNet\n","history = modelL.fit(xTrain, yTrain, epochs=10, batch_size=16, validation_data=(xVal, yVal), callbacks=[cb]) # Обучаем модель на выборке по трем классам"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gswffbh8AmEo"},"source":["# Отобразим график обучения модели\n","plt.figure(figsize=(14,7))\n","plt.plot(history.history['dice_coef'])\n","plt.plot(history.history['val_dice_coef'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Di3O-r-oEL9"},"source":["modelL.save_weights('/content/drive/My Drive/Нейронка для Иры/modelL.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YulllVQg9Dl0"},"source":["#### Распознавание"]},{"cell_type":"code","metadata":{"id":"80Nb0oVpppeG"},"source":["modelL = linearSegmentationNet(num_classes, (img_width, img_height, 3)) # Создаем моель linearSegmentationNet\n","modelL.load_weights('/content/drive/My Drive/Нейронка для Иры/modelL.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N01FiT5jkBnd"},"source":["processImage(modelL, 5, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-FC9VX4zsnJa"},"source":["### U-net\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=3623"]},{"cell_type":"code","metadata":{"id":"r-n-ivxFLKOF"},"source":["'''\n","  Функция создания сети\n","    Входные параметры:\n","    - num_classes - количество классов\n","    - input_shape - размерность карты сегментации\n","'''\n","def unet(num_classes = num_classes, input_shape= (img_width, img_height, 3)):\n","    img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n","\n","    # Block 1\n","    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n","\n","    x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n","\n","    # Block 2\n","    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n","\n","    x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n","\n","    # Block 3\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_3_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_3_out\n","\n","    x = MaxPooling2D()(block_3_out)                                        # Добавляем слой MaxPooling2D\n","\n","    # Block 4\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)        # Добавляем Conv2D-слой с 512-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_4_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_4_out\n","    x = block_4_out \n","\n","    # UP 2\n","    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 256 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = concatenate([x, block_3_out])                                      # Объединем текущий слой со слоем block_3_out\n","    x = Conv2D(256, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 256 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same')(x)\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    # UP 3\n","    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 128 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = concatenate([x, block_2_out])                                      # Объединем текущий слой со слоем block_2_out\n","    x = Conv2D(128, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    # UP 4\n","    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    x = concatenate([x, block_1_out])  # Объединем текущий слой со слоем block_1_out\n","    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","    model = Model(img_input, x) # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","    # Компилируем модель \n","    model.compile(optimizer=Adam(learning_rate=0.0005),\n","                  loss='categorical_crossentropy',\n","                  metrics=[dice_coef])\n","    \n","    return model # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiX04rSrLMd1"},"source":["modelUnet = unet(num_classes, (img_width, img_height, 3)) # Создаем модель unet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8QIEvrI9PM1"},"source":["cb = ModelCheckpoint(\r\n","    '/content/drive/My Drive/Нейронка для Иры/weightsU/',\r\n","    monitor=\"val_loss\",\r\n","    verbose=1,\r\n","    save_best_only=True,\r\n","    save_weights_only=True,\r\n","    mode=\"min\",\r\n","    save_freq=\"epoch\",\r\n","    options=None\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFlktpNPRtVC"},"source":["history = modelUnet.fit(xTrain, yTrain, epochs=100, batch_size=16, validation_data = (xVal, yVal),callbacks=[cb]) # Обучаем модель на выборке по трем классам"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAFRc5E32QAn"},"source":["modelUnet.save_weights('/content/drive/My Drive/Нейронка для Иры/modelUnet.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VaAiNqnDsxgf"},"source":["#### Распознавание"]},{"cell_type":"code","metadata":{"id":"-TaPLDbQplA8"},"source":["modelUnet = unet(num_classes, (img_width, img_height, 3)) # Создаем модель unet\n","modelUnet.load_weights('/content/drive/My Drive/Нейронка для Иры/weightsU/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KPWVBHNLhHir"},"source":["processImage(modelUnet, 5, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"09KO0jduDIu-"},"source":["### Упрощённая U-net\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=4679"]},{"cell_type":"code","metadata":{"id":"BSLJRhASDOxJ"},"source":["'''\n","  Функция создания сети\n","    Входные параметры:\n","    - num_classes - количество классов\n","    - input_shape - размерность карты сегментации\n","'''\n","def simpleUnet(num_classes = num_classes, input_shape= (img_width, img_height, 3)):\n","    img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n","\n","    # Block 1\n","    x = Conv2D(32, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 32-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(32, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 32-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n","\n","    x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n","\n","    # Block 2\n","    x = Conv2D(64, (3, 3), padding='same', name='block2_conv1')(x)         # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same', name='block2_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n","\n","    x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n","    \n","    # UP 1\n","    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)     # Добавляем Conv2DTranspose-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    # UP 2\n","    x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(x)     # Добавляем Conv2DTranspose-слой с 32-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(32, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 32-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(32, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 32-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(num_classes,(3,3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","    model = Model(img_input, x)                                            # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","    # Компилируем модель\n","    model.compile(optimizer=Adam(lr=1e-3),\n","                  loss='categorical_crossentropy',\n","                  metrics=[dice_coef])\n","    \n","    return model                                                           # Возвращаем модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQjH0JERLouR"},"source":["modelS = simpleUnet(num_classes, (img_width, img_height, 3))                                                              # Создаем модель simpleUnet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUo0ovbY-6NP"},"source":["cb = ModelCheckpoint(\r\n","    '/content/drive/My Drive/Нейронка для Иры/weightsUS/',\r\n","    monitor=\"val_loss\",\r\n","    verbose=1,\r\n","    save_best_only=True,\r\n","    save_weights_only=True,\r\n","    mode=\"min\",\r\n","    save_freq=\"epoch\",\r\n","    options=None\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w18aR1NJDoW6"},"source":["history = modelS.fit(xTrain, yTrain, epochs=100, batch_size=16, validation_data = (xVal, yVal), callbacks=[cb]) # Обучаем модель на выборке по трем классам"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Spyguz1voovb"},"source":["#modelS.save_weights('/content/drive/My Drive/Нейронка для Иры/modelS.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"djINNTLqnymg"},"source":["#### Распознавание"]},{"cell_type":"code","metadata":{"id":"e_d3FCctpdpN"},"source":["modelS = simpleUnet(num_classes, (img_width, img_height, 3))    \n","modelS.load_weights('/content/drive/My Drive/Нейронка для Иры/weightsUS/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFs_7GTgK5Md"},"source":["def fillhole(input_image):\r\n","    '''\r\n","    input gray binary image  get the filled image by floodfill method\r\n","    Note: only holes surrounded in the connected regions will be filled.\r\n","    :param input_image:\r\n","    :return:\r\n","    '''\r\n","    im_flood_fill = input_image.copy()\r\n","    h, w = input_image.shape[:2]\r\n","    mask = np.zeros((h + 2, w + 2), np.uint8)\r\n","    im_flood_fill = im_flood_fill.astype(\"uint8\")\r\n","    cv.floodFill(im_flood_fill, None, (0, 0), 255)\r\n","    im_flood_fill_inv = cv.bitwise_not(im_flood_fill)\r\n","    img_out = input_image | im_flood_fill_inv\r\n","    return img_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"keNgafgKK1HF"},"source":["# Функция визуализации сегментированных изображений\r\n","def processImage(model, count = 1, n_classes = 2):\r\n","  indexes = np.random.randint(0, len(xVal), count) # Получаем count случайных индексов\r\n","  fig, axs = plt.subplots(4, count, figsize=(25, 15)) #Создаем полотно из n графиков\r\n","  for i,idx in enumerate(indexes): # Проходим по всем сгенерированным индексам\r\n","    predict = np.array(model.predict(xVal[idx].reshape(1, img_width, img_height, 3))) # Предиктим картику\r\n","    pr = predict[0] # Берем нулевой элемент из перидкта\r\n","    pr1 = [] # Пустой лист под сегментированную картинку из predicta\r\n","    pr2 = [] # Пустой лист под сегменитрованную картинку из yVal\r\n","    pr = pr.reshape(-1, n_classes) # Решейпим предикт\r\n","    yr = yVal[idx].reshape(-1, n_classes) # Решейпим yVal\r\n","    for k in range(len(pr)): # Проходим по всем уровням (количесвто классов)\r\n","      pr1.append(index2color(pr[k])) # Переводим индекс в писксель\r\n","      pr2.append(index2color(yr[k])) # Переводим индекс в писксель\r\n","    pr1 = np.array(pr1) # Преобразуем в numpy\r\n","    pr1 = pr1.reshape(img_width, img_height,3) # Решейпим к размеру изображения\r\n","    pr2 = np.array(pr2) # Преобразуем в numpy\r\n","    pr2 = pr2.reshape(img_width, img_height,3) # Решейпим к размеру изображения\r\n","    pr = fillhole(pr1)\r\n","    pr = Image.fromarray(pr.astype('uint8'))\r\n","    img = Image.fromarray(pr1.astype('uint8')) # Получаем картику из предикта\r\n","    \r\n","    axs[0,i].imshow(img.convert('RGBA')) # Отображаем на графике в первой линии\r\n","    axs[0,i].axis('off')\r\n","    axs[1,i].imshow(pr.convert('RGBA')) # Отображаем на графике в первой линии\r\n","    axs[1,i].axis('off')\r\n","    axs[2,i].imshow(Image.fromarray(pr2.astype('uint8'))) # Отображаем на графике во второй линии сегментированное изображение из yVal\r\n","    axs[2,i].axis('off')\r\n","    axs[3,i].imshow(Image.fromarray(xVal[idx].astype('uint8'))) # Отображаем на графике в третьей линии оригинальное изображение        \r\n","    axs[3,i].axis('off')\r\n","  plt.show()  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIQyKGUHD2tG"},"source":["processImage(modelS, 5, num_classes)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NHDbEEibA6uf"},"source":["### Расширенная U-net\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=4790"]},{"cell_type":"code","metadata":{"id":"QOjFjIERBFId"},"source":["'''\n","  Функция создания сети\n","    Входные параметры:\n","    - num_classes - количество классов\n","    - input_shape - размерность карты сегментации\n","'''\n","def unetWithMask(num_classes = num_classes, input_shape= (216, img_height,3)):\n","    img_input = Input(input_shape)                                      # Создаем входной слой с размерностью input_shape\n","\n","    # Block 1\n","    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)      # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    block_1_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_1_out\n","    \n","    block_1_out_mask = Conv2D(64, (1, 1), padding='same')(block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n","\n","    x = MaxPooling2D()(block_1_out) # Добавляем слой MaxPooling2D\n","\n","    # Block 2\n","    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)     # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)     # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    block_2_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_2_out\n","\n","    block_2_out_mask = Conv2D(128, (1, 1), padding='same')(block_2_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_2_out_mask\n","    \n","    x = MaxPooling2D()(block_2_out)                                     # Добавляем слой MaxPooling2D\n","\n","    # Block 3\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    block_3_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_3_out\n","\n","    block_3_out_mask = Conv2D(256, (1, 1), padding='same')(block_3_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_3_out_mask\n","        \n","    x = MaxPooling2D()(block_3_out)                                     # Добавляем слой MaxPooling2D\n","\n","     # Block 4\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    block_4_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_4_out\n","\n","    block_4_out_mask = Conv2D(512, (1, 1), padding='same')(block_4_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_4_out_mask\n","            \n","    x = MaxPooling2D()(block_4_out)                                     # Добавляем слой MaxPooling2D\n","\n","    # Block 5\n","    x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","    \n","    for_pretrained_weight = MaxPooling2D()(x)                           # Добавляем слой MaxPooling2D\n"," \n","    # UP 1\n","    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = concatenate([x, block_4_out, block_4_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n","    x = Conv2D(512, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    # UP 2\n","    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 256 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = concatenate([x, block_3_out, block_3_out_mask])                 # Объединем текущий слой со слоем block_3_out и слоем-маской block_3_out_mask\n","    x = Conv2D(256, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    # UP 3\n","    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 128 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = concatenate([x, block_2_out, block_2_out_mask])                 # Объединем текущий слой со слоем block_2_out и слоем-маской block_2_out_mask\n","    x = Conv2D(128, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                           # Добавляем слой Activation\n","\n","    # UP 4\n","    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n","    x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                          # Добавляем слой Activation\n","\n","    x = concatenate([x, block_1_out, block_1_out_mask])                # Объединем текущий слой со слоем block_1_out и слоем-маской block_1_out_mask\n","    x = Conv2D(64, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                          # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                          # Добавляем слой Activation\n","\n","    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","    model = Model(img_input, x)                                        # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","    # Компилируем модель \n","    model.compile(optimizer=Adam(),\n","                  loss='categorical_crossentropy',\n","                  metrics=[dice_coef])\n","    \n","    return model                                                       # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jegmvYcOMC1e"},"source":["modelM3 = unetWithMask(num_classes, (img_width, img_height,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXHrGrKDBwPQ"},"source":["history = modelM3.fit(xTrain, yTrain, epochs=20, batch_size=16, validation_data = (xVal, yVal)) #  Обучаем модель на выборке по трем классам на полноразмерных изображениях"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7L_vHc2UGro3"},"source":["#modelM3.save_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelM3.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0V_SvtOp__C"},"source":["#### Распознавание"]},{"cell_type":"code","metadata":{"id":"xA5zxadGqFkK"},"source":["modelM3 = unetWithMask(num_classes, (img_width, img_height,3))\n","modelM3.load_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelM3.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bZ5cAEsIqFEC"},"source":["processImage(modelM3, 5, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yNmo207rflRW"},"source":["# Сегментация самолетов\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=5174"]},{"cell_type":"code","metadata":{"id":"66F4EJuffnRb"},"source":["# Глобальные параметры\n","img_width = 176 # Ширина уменьшенной картинки \n","img_height =  320 # Высота уменьшенной картинки \n","directory = '/content/drive/My Drive/Базы/Самолеты/' # Указываем путь к обучающей выборке с оригинальными изображения\n","num_classes = 2 # Количество классов на изображении"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2uJ9oIQKf0fs"},"source":["## Загрузка изображений"]},{"cell_type":"code","metadata":{"id":"N-2N0mcEf2nT"},"source":["images_airplane = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n","\n","cur_time = time.time() # Засекаем текущее время\n","for filename in sorted(os.listdir(directory + 'Самолеты')): # Проходим по всем файлам в каталоге по указанному пути     \n","    images_airplane.append(image.load_img(os.path.join(directory + 'Самолеты',filename),\n","                                       target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n","print ('Обучающая выборка загржуена. Время загрузки: ', time.time() - cur_time, 'c', sep='') # Отображаем время загрузки картинок обучающей выборки"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-0-5dgEgF41"},"source":["n = 5 # Количество выводимых случайных картинок\n","fig, axs = plt.subplots(1, n, figsize=(25, 5)) #Создаем полотно из n графиков\n","for i in range(n): # Выводим в цикле n случайных изображений\n","  img = random.choice(images_airplane) # Выбираем случайное фото для отображения\n","  axs[i].imshow(img) # Отображаем фото\n","  axs[i].axis('off')  \n","plt.show() #Показываем изображения"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KO-fJecgKi_"},"source":["segments_airplane = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n","\n","cur_time = time.time() # Засекаем текущее время\n","for filename in sorted(os.listdir(directory + 'Segment')): # Проходим по всем файлам в каталоге по указанному пути     \n","    segments_airplane.append(image.load_img(os.path.join(directory + 'Segment',filename),\n","                                       target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n","print ('Обучающая выборка загржуена. Время загрузки: ', time.time() - cur_time, 'c', sep='') # Отображаем время загрузки картинок обучающей выборки"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GRG5IXMpgRry"},"source":["n = 5 # Количество выводимых случайных картинок\n","fig, axs = plt.subplots(1, n, figsize=(25, 5)) #Создаем полотно из n графиков\n","for i in range(n): # Выводим в цикле n случайных изображений\n","  img = random.choice(segments_airplane) # Выбираем случайное фото для отображения\n","  axs[i].imshow(img) # Отображаем фото\n","  axs[i].axis('off')\n","plt.show() #Показываем изображения"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bxk5YLHMgXl_"},"source":["## Создание выборки\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=5253"]},{"cell_type":"code","metadata":{"id":"3qkSZ7VmgY9D"},"source":["# Функция преобразования пикселя сегментированного изображения в индекс (6 классов)\n","def color2index(color):\n","    index=0\n","    if (color[0] + color[1] + color[2]) > 20  : index = 1 # самолет    \n","    return index  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXs3W5I4gaon"},"source":["def index2color(index2):\n","    index = np.argmax(index2)\n","    color=[]\n","    if index == 0:\n","        color = [0, 0, 0]  # фон\n","    elif index == 1:\n","        color = [255, 0, 0]  # самолет\n","    return color "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luxXYLxogcRU"},"source":["# Функция перевода индекса пикслея в to_categorical\n","def rgbToohe(y, num_classes): \n","  y2 = y.copy() # Создаем копию входного массива\n","  y = y.reshape(y.shape[0] * y.shape[1], 3) # Решейпим в двумерный массив\n","  yt = [] # Создаем пустой лист\n","  for i in range(len(y)): # Проходим по всем трем канала изображения\n","    yt.append(utils.to_categorical(color2index(y[i]), num_classes=num_classes)) # Переводим пиксели в индексы и преобразуем в OHE\n","  yt = np.array(yt) # Преобразуем в numpy\n","  yt = yt.reshape(y2.shape[0], y2.shape[1], num_classes) # Решейпим к исходныму размеру\n","  return yt # Возвращаем сформированный массив"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JuiZREgkgh6J"},"source":["# Функция формирования yTrain\n","def yt_prep(data, num_classes):\n","  yTrain = [] # Создаем пустой список под карты сегметации\n","  for seg in data: # Пробегаем по всем файлам набора с сегминтированными изображениями\n","    y = image.img_to_array(seg) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n","    y = rgbToohe(y, num_classes) # Получаем OHE-представление сформированного массива\n","    yTrain.append(y) # Добавляем очередной элемент в yTrain\n","    if len(yTrain) % 100 == 0: # Каждые 100 шагов\n","      print(len(yTrain)) # Выводим количество обработанных изображений\n","  return np.array(yTrain) # Возвращаем сформированный yTrain"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBVZe0W1gkig"},"source":["xTrain = [] # Создаем пустой список под обучающую выборку\n","for img in images_airplane: \n","    x = image.img_to_array(img) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n","    xTrain.append(x) # Добавляем очередной элемент в xTrain\n","xTrain = np.array(xTrain) # Переводим в numpy\n","print(xTrain.shape) # Размерность обучающей выборки"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwGL0UhlglF9"},"source":["cur_time = time.time()\n","yTrain = yt_prep(segments_airplane, num_classes) \n","print('Время обработки: ', round(time.time() - cur_time, 2),'c')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cm6q79OaPEHq"},"source":["yTrain.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVf-ZmRugynC"},"source":["y_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qld2ZK-hg4c6"},"source":["## Обучение модели\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=5332"]},{"cell_type":"code","metadata":{"id":"69o-S6oZg6E7"},"source":["'''\n","  Функция создания сети\n","    Входные параметры:\n","    - num_classes - количество классов\n","    - input_shape - размерность карты сегментации\n","'''\n","def unet(num_classes = num_classes, input_shape= (img_width, img_height,3)):\n","    img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n","\n","    # Block 1\n","    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n","\n","    x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n","\n","    # Block 2\n","    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n","\n","    x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n","\n","    # Block 3\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_3_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_3_out\n","\n","    x = MaxPooling2D()(block_3_out)                                        # Добавляем слой MaxPooling2D\n","\n","    # Block 4\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)        # Добавляем Conv2D-слой с 512-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    block_4_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_4_out\n","    x = block_4_out \n","\n","    # UP 2\n","    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 256 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = concatenate([x, block_3_out])                                      # Объединем текущий слой со слоем block_3_out\n","    x = Conv2D(256, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 256 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(256, (3, 3), padding='same')(x)\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    # UP 3\n","    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 128 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = concatenate([x, block_2_out])                                      # Объединем текущий слой со слоем block_2_out\n","    x = Conv2D(128, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 128 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    # UP 4\n","    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    x = concatenate([x, block_1_out])  # Объединем текущий слой со слоем block_1_out\n","    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x) # Добавляем слой Activation\n","\n","    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","    model = Model(img_input, x) # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","    # Компилируем модель \n","    model.compile(optimizer=Adam(),\n","                  loss='categorical_crossentropy',\n","                  metrics=[dice_coef])\n","    \n","    return model # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8SRDXXJOZf9"},"source":["modelAir = unet(2,(176,320,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Db49uTk0g6xj"},"source":["history = modelAir.fit(x_train, y_train, epochs=35, batch_size=16, validation_data = (x_val, y_val)) # Обучаем модель на выборке по трем классам"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8yZ3VPj2GgP"},"source":["modelAir.save_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelAir.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RN20gYTeg8lG"},"source":["## Распознавание"]},{"cell_type":"code","metadata":{"id":"kF1SWpsa2NGf"},"source":["modelAir = unet(2, (img_width, img_height,3))\n","modelAir.load_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelAir.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_lI88MEg-X-"},"source":["count = 5\n","n_classes = 2\n","indexes = np.random.randint(0, len(x_val), count) # Получаем count случайных индексов\n","fig, axs = plt.subplots(2, count, figsize=(25, 5)) #Создаем полотно из n графиков\n","for i,idx in enumerate(indexes): # Проходим по всем сгенерированным индексам\n","  predict = np.array(modelAir.predict(x_val[idx].reshape(1, img_width, img_height, 3))) # Предиктим картику\n","  pr = predict[0] # Берем нулевой элемент из перидкта\n","  pr1 = [] # Пустой лист под сегментированную картинку из predicta\n","  pr = pr.reshape(-1, n_classes) # Решейпим предикт\n","  for k in range(len(pr)): # Проходим по всем уровням (количесвто классов)\n","    pr1.append(index2color(pr[k])) # Переводим индекс в писксель\n","  pr1 = np.array(pr1) # Преобразуем в numpy\n","  pr1 = pr1.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n","  img = Image.fromarray(pr1.astype('uint8')) # Получаем картику из предикта\n","  axs[0,i].imshow(img.convert('RGBA')) # Отображаем на графике в первой линии\n","  axs[0,i].axis('off')\n","  axs[1,i].imshow(Image.fromarray(x_val[idx].astype('uint8'))) # Отображаем на графике в третьей линии оригинальное изображение        \n","  axs[1,i].axis('off')\n","plt.show() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AXMJXHYKhBGk"},"source":["### Наложение маски\n","\n","*Разбор данного раздела:* https://youtu.be/PCTynVb9TbI?t=6481"]},{"cell_type":"code","metadata":{"id":"GQvbUxZUhC0i"},"source":["seg = Image.fromarray(pr1.astype('uint8')).convert('RGBA')\n","plt.imshow(seg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbt6sgGtIUnX"},"source":["plt.imshow(Image.fromarray(x_val[idx].astype('uint8')))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBA3Z_T8IV7Q"},"source":["mask = np.array(seg)\n","mask[mask[:,:,0] <= 10] = [0, 0, 0, 0]\n","mask[mask[:,:,0] > 10] = [0, 150, 0, 150]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTRdWOqPIYju"},"source":["plt.figure(figsize=(14,7))\n","img2 = Image.fromarray(x_val[idx].astype('uint8'))\n","img = Image.fromarray(mask).convert('RGBA')\n","img2.paste(img, (0, 0),img)\n","plt.imshow(img2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edX-zTek_0KY"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0wu6prpMyTm"},"source":["import cv2 as cv\r\n","from PIL import Image\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","img = cv.imread('/content/drive/My Drive/segmentation/predicted/advanced_UNET/дог12.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRQg7HhM_47n"},"source":["x1 = img.shape[0]\r\n","y1 = img.shape[1]\r\n","\r\n","itemindex = np.array(np.where(img > 10))\r\n","\r\n","minH = min(itemindex[0]) \r\n","maxH = max(itemindex[0])\r\n","minW = min(itemindex[1])\r\n","maxW = max(itemindex[1])\r\n","\r\n","pts = np.float32([[minW,minH],[maxW,minH],[minW,maxH],[maxW,maxH]])\r\n","img_cropped = img[minH:maxH, minW:maxW]\r\n","plt.figure(figsize = (20, 20))\r\n","plt.imshow(img_cropped)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHyWGylIEKXl"},"source":["height = img_cropped.shape[0]\r\n","width = img_cropped.shape[1]\r\n","\r\n","def order_points(pts):\r\n","\t# initialzie a list of coordinates that will be ordered\r\n","\t# such that the first entry in the list is the top-left,\r\n","\t# the second entry is the top-right, the third is the\r\n","\t# bottom-right, and the fourth is the bottom-left\r\n","\trect = np.zeros((4, 2), dtype = \"float32\")\r\n","\t# the top-left point will have the smallest sum, whereas\r\n","\t# the bottom-right point will have the largest sum\r\n","\ts = pts.sum(axis = 1)\r\n","\trect[0] = pts[np.argmin(s)]\r\n","\trect[2] = pts[np.argmax(s)]\r\n","\t# now, compute the difference between the points, the\r\n","\t# top-right point will have the smallest difference,\r\n","\t# whereas the bottom-left will have the largest difference\r\n","\tdiff = np.diff(pts, axis = 1)\r\n","\trect[1] = pts[np.argmin(diff)]\r\n","\trect[3] = pts[np.argmax(diff)]\r\n","\t# return the ordered coordinates\r\n","\treturn rect\r\n","\r\n","def four_point_transform(image, pts):\r\n","\t# obtain a consistent order of the points and unpack them\r\n","\t# individually\r\n","\trect = order_points(pts)\r\n","\t(tl, tr, br, bl) = rect\r\n","\t# compute the width of the new image, which will be the\r\n","\t# maximum distance between bottom-right and bottom-left\r\n","\t# x-coordiates or the top-right and top-left x-coordinates\r\n","\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\r\n","\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\r\n","\tmaxWidth = max(int(widthA), int(widthB))\r\n","\t# compute the height of the new image, which will be the\r\n","\t# maximum distance between the top-right and bottom-right\r\n","\t# y-coordinates or the top-left and bottom-left y-coordinates\r\n","\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\r\n","\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\r\n","\tmaxHeight = max(int(heightA), int(heightB))\r\n","\t# now that we have the dimensions of the new image, construct\r\n","\t# the set of destination points to obtain a \"birds eye view\",\r\n","\t# (i.e. top-down view) of the image, again specifying points\r\n","\t# in the top-left, top-right, bottom-right, and bottom-left\r\n","\t# order\r\n","\tdst = np.array([\r\n","\t\t[0, 0],\r\n","\t\t[maxWidth - 1, 0],\r\n","\t\t[maxWidth - 1, maxHeight - 1],\r\n","\t\t[0, maxHeight - 1]], dtype = \"float32\")\r\n","\t# compute the perspective transform matrix and then apply it\r\n","\tM = cv.getPerspectiveTransform(rect, dst)\r\n","\twarped = cv.warpPerspective(image, M, (maxWidth, maxHeight))\r\n","\t# return the warped image\r\n","\treturn warped\r\n","\r\n","def get_coordinates_logic(img):\r\n","  factor = 180\r\n","  thresh = 10\r\n","  x_scale = width - factor + 1\r\n","  y_scale = height - factor + 1\r\n","  temp_img = img[0:factor, 0:factor, :]\r\n","  w1 = min(np.array(np.where(temp_img > thresh))[0])\r\n","  h1 = min(np.array(np.where(temp_img > thresh))[0])\r\n","  temp_img = img[0:factor, -factor:, :]\r\n","  w2 = max(np.array(np.where(temp_img > thresh))[1]) + x_scale\r\n","  h2 = min(np.array(np.where(temp_img > thresh))[0])\r\n","  temp_img = img[-factor:, -factor:, :]\r\n","  w3 = max(np.array(np.where(temp_img > thresh))[1]) + x_scale\r\n","  h3 = max(np.array(np.where(temp_img > thresh))[0]) + y_scale\r\n","  temp_img = img[-factor:, 0:factor, :]\r\n","  w4 = min(np.array(np.where(temp_img > thresh))[1])\r\n","  h4 = max(np.array(np.where(temp_img > thresh))[0]) + y_scale\r\n","\r\n","  return w1, w2, w3, w4, h1, h2, h3, h4\r\n","\r\n","\r\n","w1, w2, w3, w4, h1, h2, h3, h4 = get_coordinates_logic(img_cropped)\r\n","\r\n","\r\n","dst = four_point_transform(img_cropped, np.array([[w1, h1], [w2, h2], [w3, h3], [w4, h4]]))\r\n","plt.subplot(121),plt.imshow(img_cropped),plt.title('Input')\r\n","plt.subplot(122),plt.imshow(dst),plt.title('Output')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLyxcAPr2dGC"},"source":["def check_pixels(img, i, j, thresh):\r\n","  condition = False\r\n","  value = img[i:i+10, j:j+10, :].sum()\r\n","  if value < thresh:\r\n","    return True\r\n","  return False\r\n","\r\n","def filter_image(img, thresh):\r\n","  img = img.copy()\r\n","  rows = range(img.shape[0] - 10)\r\n","  columns = range(img.shape[1] - 10)\r\n","  for i in rows:\r\n","    for j in columns:\r\n","      if check_pixels(img, i, j, thresh * 3 * 100) or img[i, j, :].sum() == 0:\r\n","        img[i, j, :] = 255\r\n","\r\n","  return img\r\n","      \r\n","img_processed = filter_image(dst, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGhnTYRrLpJJ"},"source":["plt.figure(figsize = (20, 20))\r\n","plt.imshow(img_processed)"],"execution_count":null,"outputs":[]}]}