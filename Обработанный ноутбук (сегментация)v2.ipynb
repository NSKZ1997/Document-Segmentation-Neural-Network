{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Обработанный ноутбук (сегментация)v2.ipynb","provenance":[{"file_id":"1Bcw6u2pTbwaJdW2xqUUr9hcQK1KANGtz","timestamp":1612967523689},{"file_id":"1Acjkzzm1iK_oWWLv1efUWgi59YAJOEL8","timestamp":1611856098425},{"file_id":"15Gz0K4HH8ZDVQOgfhqrV9RAdNhIKnA16","timestamp":1604320556177},{"file_id":"1spLdFAE7dD65wmjN43teuHSEui7yxhjT","timestamp":1595339226511},{"file_id":"1Tk0AMA0poD-YwGwSdu1NYyrPUNsWxkPD","timestamp":1590142695002},{"file_id":"1e6l5b8NIQcBnM3Rmc34sZiXOwipangYY","timestamp":1590142651559},{"file_id":"1aLOO2J4BbV8SH7kaXwqUt6PJ9uVrmvH9","timestamp":1589980181817},{"file_id":"1N6mk6WSkgriPSaK9NFNtCIBPnzfsdTfI","timestamp":1584996748180},{"file_id":"1YSaoxYU6Hws1H2vwQFLd6Wp9DSpGJo-P","timestamp":1577104513613},{"file_id":"136NdAsm_5wklbqYk46_2kSjrSD20XE97","timestamp":1571739357556},{"file_id":"1bFUtApObvywutBFsJlyZwsU-HbxZpCUj","timestamp":1563483711144}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NguG3E7fNQDC"},"source":["# Подключение бибилиотек"]},{"cell_type":"code","metadata":{"id":"0hyWYiPqLdez"},"source":["from tensorflow.keras.models import Model # Импортируем модели keras: Model\n","from tensorflow.keras.layers import * # Импортируем стандартные слои keras\n","from tensorflow.keras import backend as K # Импортируем модуль backend keras'а\n","from tensorflow.keras.optimizers import Adam # Импортируем оптимизатор Adam\n","from tensorflow.keras import utils # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n","import tensorflow as tf\n","from google.colab import files # Импортируем Модуль files для работы с файлами\n","import matplotlib.pyplot as plt # Импортируем модуль pyplot библиотеки matplotlib для построения графиков\n","from tensorflow.keras.preprocessing import image # Импортируем модуль image для работы с изображениями\n","import numpy as np # Импортируем библиотеку numpy\n","from sklearn.model_selection import train_test_split\n","import time\n","import random\n","import shutil\n","import os # Импортируем библиотеку os для раоты с фаловой системой\n","from PIL import Image # импортируем модель Image для работы с изображениями\n","import seaborn as sns\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import load_model, save_model\n","import tqdm\n","\n","import cv2 as cv\n","from PIL import Image\n","sns.set_style('darkgrid')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xP4-NkAt96gv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613151445859,"user_tz":-180,"elapsed":22331,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"f1b25dc2-6fc2-43ab-850e-f9c6daa531f2"},"source":["from google.colab import drive # Подключаем гугл-диск\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1z0tvvy1THBj"},"source":["# Сегментация документов"]},{"cell_type":"markdown","metadata":{"id":"oxHD9MO-sM_u"},"source":["## Загрузка картинок"]},{"cell_type":"code","metadata":{"id":"CbNtynGfV27x"},"source":["# Глобальные параметры\n","num_classes = 2 # Задаем количество классов на изображении\n","directory = '/content/drive/My Drive/segmentation/' # Указываем путь к обучающей выборке с оригинальными изображения"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QYxjEPjtVRDy"},"source":["### Оригинальные изображения"]},{"cell_type":"code","metadata":{"id":"AbK0KhHFvebD"},"source":["def order_points(pts):\n","\t# initialzie a list of coordinates that will be ordered\n","\t# such that the first entry in the list is the top-left,\n","\t# the second entry is the top-right, the third is the\n","\t# bottom-right, and the fourth is the bottom-left\n","\trect = np.zeros((4, 2), dtype = \"float32\")\n","\t# the top-left point will have the smallest sum, whereas\n","\t# the bottom-right point will have the largest sum\n","\ts = pts.sum(axis = 1)\n","\trect[0] = pts[np.argmin(s)]\n","\trect[2] = pts[np.argmax(s)]\n","\t# now, compute the difference between the points, the\n","\t# top-right point will have the smallest difference,\n","\t# whereas the bottom-left will have the largest difference\n","\tdiff = np.diff(pts, axis = 1)\n","\trect[1] = pts[np.argmin(diff)]\n","\trect[3] = pts[np.argmax(diff)]\n","\t# return the ordered coordinates\n","\treturn rect\n","\n","def four_point_transform(image, pts):\n","\t# obtain a consistent order of the points and unpack them\n","\t# individually\n","\trect = order_points(pts)\n","\t(tl, tr, br, bl) = rect\n","\t# compute the width of the new image, which will be the\n","\t# maximum distance between bottom-right and bottom-left\n","\t# x-coordiates or the top-right and top-left x-coordinates\n","\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n","\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n","\tmaxWidth = max(int(widthA), int(widthB))\n","\t# compute the height of the new image, which will be the\n","\t# maximum distance between the top-right and bottom-right\n","\t# y-coordinates or the top-left and bottom-left y-coordinates\n","\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n","\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n","\tmaxHeight = max(int(heightA), int(heightB))\n","\t# now that we have the dimensions of the new image, construct\n","\t# the set of destination points to obtain a \"birds eye view\",\n","\t# (i.e. top-down view) of the image, again specifying points\n","\t# in the top-left, top-right, bottom-right, and bottom-left\n","\t# order\n","\tdst = np.array([\n","\t\t[0, 0],\n","\t\t[maxWidth - 1, 0],\n","\t\t[maxWidth - 1, maxHeight - 1],\n","\t\t[0, maxHeight - 1]], dtype = \"float32\")\n","\t# compute the perspective transform matrix and then apply it\n","\tM = cv.getPerspectiveTransform(rect, dst)\n","\twarped = cv.warpPerspective(image, M, (maxWidth, maxHeight))\n","\t# return the warped image\n","\treturn warped\n","\n","def get_coordinates_logic(img, factor = 100):\n","  color = (128, 0, 128)\n","  width = img.shape[1]\n","  height = img.shape[0]\n","  x_scale = width - factor + 1\n","  y_scale = height - factor + 1\n","\n","  try:\n","    temp_img = img[0:factor, 0:factor, :]\n","    w1 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[1])\n","    h1 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[0])\n","    temp_img = img[0:factor, -factor:, :]\n","    w2 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) + x_scale\n","    h2 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[0])\n","    temp_img = img[-factor:, -factor:, :]\n","    w3 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) + x_scale\n","    h3 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) + y_scale\n","    temp_img = img[-factor:, 0:factor, :]\n","    w4 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[1])\n","    h4 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) + y_scale\n","  except:\n","    w1, w2, w3, w4, h1, h2, h3, h4 = get_coordinates_logic(img, factor = factor + 50)\n","  \n","  return w1, w2, w3, w4, h1, h2, h3, h4\n","\n","def process_img(img):\n","  img = img.copy()\n","  temp = img.copy()\n","  height = img.shape[0]\n","  width = img.shape[1]\n","\n","  itemindex = np.array(np.where(np.all(img == (128, 0, 128), axis=-1)))\n","\n","  minH = min(itemindex[0]) \n","  maxH = max(itemindex[0])\n","  minW = min(itemindex[1])\n","  maxW = max(itemindex[1])\n","\n","  pts = np.float32([[minW,minH],[maxW,minH],[minW,maxH],[maxW,maxH]])\n","  img_cropped = img[minH:maxH, minW:maxW]\n","\n","  w1, w2, w3, w4, h1, h2, h3, h4 = get_coordinates_logic(img_cropped)\n","\n","  result = four_point_transform(img_cropped, np.array([[w1, h1], [w2, h2], [w3, h3], [w4, h4]]))\n","  return result\n","\n","def index2color(segment_img, actual_img, final_mode = False):\n","  new_img = np.zeros_like(actual_img)\n","\n","  segment_img = np.round(segment_img)\n","  for i in range(segment_img.shape[0]):\n","    for j in range(segment_img.shape[1]):\n","      if segment_img[i, j, 0] == 1:\n","        new_img[i, j, 0] = 128 #R\n","        new_img[i, j, 1] = 0   #G\n","        new_img[i, j, 2] = 128 #B\n","      elif segment_img[i, j, 1] == 1:\n","        for channel in range(3):\n","          new_img[i, j, channel] = actual_img[i, j, channel]\n","  if final_mode:\n","    new_img = process_img(new_img)\n","  return np.array(new_img)\n","\n","def image_preprocessing(img):\n","  img = cv.resize(img, (img_height, img_width), interpolation = cv.INTER_NEAREST)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1VagEofdhx5n"},"source":["xTrain = np.load(\"/content/drive/My Drive/segmentation/arrays/xTrain_fixed.npy\")\r\n","xVal = np.load(\"/content/drive/My Drive/segmentation/arrays/xVal_fixed.npy\")\r\n","\r\n","img_width = xTrain.shape[1] # Ширина уменьшенной картинки \r\n","img_height = xTrain.shape[2] # Высота уменьшенной картинки "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVQl7jXHiDEi"},"source":["yTrain = np.load(\"/content/drive/My Drive/segmentation/arrays/yTrain_fixed.npy\")\r\n","yVal = np.load(\"/content/drive/My Drive/segmentation/arrays/yVal_fixed.npy\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"biK8gqWmuzdt"},"source":["# xTrain_new2 = []\r\n","# yTrain_new2 = []\r\n","# to_delete = [59, 103]\r\n","# for i in range(len(xTrain)):\r\n","#   if i not in to_delete:\r\n","#     xTrain_new2.append(xTrain[i])\r\n","#     yTrain_new2.append(yTrain[i])\r\n","\r\n","# xTrain_new2 = np.array(xTrain_new2)\r\n","# yTrain_new2 = np.array(yTrain_new2)\r\n","\r\n","# xTrain_new, xVal_new, yTrain_new, yVal_new = train_test_split(xTrain_new2, yTrain_new2, test_size = 0.1, shuffle = False)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/xTrain_fixed.npy\", xTrain_new)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/yTrain_fixed.npy\", yTrain_new)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/xVal_fixed.npy\", xVal_new)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/yVal_fixed.npy\", yVal_new)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrOmh4jH6tIv"},"source":["# xTrain_new2 = []\r\n","# yTrain_new2 = []\r\n","# to_delete = [59, 103]\r\n","# for i in range(len(xTrain_new)):\r\n","#   if i not in to_delete:\r\n","#     xTrain_new2.append(xTrain_new[i])\r\n","#     yTrain_new2.append(yTrain_new[i])\r\n","\r\n","# xTrain_new2 = np.array(xTrain_new2)\r\n","# yTrain_new2 = np.array(yTrain_new2)\r\n","\r\n","# xTrain_new2, xVal_new2, yTrain_new2, yVal_new2 = train_test_split(xTrain_new2, yTrain_new2, test_size = 0.1, shuffle = False)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/xTrain_fixed.npy\", xTrain_new2)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/yTrain_fixed.npy\", yTrain_new2)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/xVal_fixed.npy\", xVal_new2)\r\n","# np.save(\"/content/drive/My Drive/segmentation/arrays/yVal_fixed.npy\", yVal_new2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJKwsGPHtQib"},"source":["# xTrain = np.delete(xTrain, 15, 0)\r\n","# yTrain = np.delete(xTrain, 15, 0)\r\n","# xTrain = np.delete(xTrain, 60, 0)\r\n","# yTrain = np.delete(xTrain, 60, 0)\r\n","# xTrain = np.delete(xTrain, 73, 0)\r\n","# yTrain = np.delete(xTrain, 73, 0)\r\n","# xTrain = np.delete(xTrain, 90, 0)\r\n","# yTrain = np.delete(xTrain, 90, 0)\r\n","# xTrain = np.delete(xTrain, 175, 0)\r\n","# yTrain = np.delete(xTrain, 175, 0)\r\n","# xTrain = np.delete(xTrain, 181, 0)\r\n","# yTrain = np.delete(xTrain, 181, 0)\r\n","# xTrain = np.delete(xTrain, 207, 0)\r\n","# yTrain = np.delete(xTrain, 207, 0)\r\n","# xTrain = np.delete(xTrain, 217, 0)\r\n","# yTrain = np.delete(xTrain, 217, 0)\r\n","# xTrain = np.delete(xTrain, 225, 0)\r\n","# yTrain = np.delete(xTrain, 225, 0)\r\n","# xTrain = np.delete(xTrain, 234, 0)\r\n","# yTrain = np.delete(xTrain, 234, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bJchJ4wlL2M"},"source":["def random_crop(image, crop_size):\r\n","    dx_start, dx_end, dy_start, dy_end = crop_size[0], crop_size[1], crop_size[2], crop_size[3]\r\n","    return cv.resize(image[dy_start:img_height-dy_end, dx_start:img_width-dx_end, :], (img_height, img_width), interpolation = cv.INTER_NEAREST)\r\n","\r\n","def rotate(img, angle):\r\n","    (height, width) = img.shape[:2]\r\n","    (cent_x, cent_y) = (width // 2, height // 2)\r\n","\r\n","    mat = cv.getRotationMatrix2D((cent_x, cent_y), -angle, 1.0)\r\n","    cos = np.abs(mat[0, 0])\r\n","    sin = np.abs(mat[0, 1])\r\n","\r\n","    n_width = int((height * sin) + (width * cos))\r\n","    n_height = int((height * cos) + (width * sin))\r\n","\r\n","    mat[0, 2] += (n_width / 2) - cent_x\r\n","    mat[1, 2] += (n_height / 2) - cent_y\r\n","\r\n","    return cv.warpAffine(img, mat, (n_width, n_height))\r\n","\r\n","def process_image(image, crop_size, angle, segment, normalize, flip_h):\r\n","  if normalize:\r\n","    image = image/255\r\n","  image = rotate(image, angle)\r\n","  image = random_crop(image, crop_size)\r\n","  if flip_h > 0.5:\r\n","    image = np.flip(image, axis = 1)\r\n","\r\n","  if segment:\r\n","    image = rgbToohe(image)\r\n","  return image\r\n","\r\n","class counter: #Класс для создания np.seed(), что бы действительно генерились картинки рандомно и стабильно, в соответствии друг с другом\r\n","  def __init__(self): #Seed должен каждый раз генериться новый, по этому мы его будем увеличивать через класс.\r\n","    self.count = 0\r\n","    self.even = True\r\n","\r\n","  def __call__(self): #Вызов счетчика (увеличивается/меняет значение после каждого второго вызова)\r\n","    if self.even:\r\n","      self.count += 1\r\n","      self.even = False\r\n","    else:\r\n","      self.even = True\r\n","    return self.count\r\n","\r\n","generate_seed = counter()\r\n","\r\n","def image_generator(data, crop_size = 20, angle = 3, batch_size = 2, segment = False, normalize = True):\r\n","  index = 0\r\n","  while True:\r\n","    np.random.seed(generate_seed())\r\n","    crop_size_x1 = np.random.randint(0, crop_size)\r\n","    crop_size_x2 = np.random.randint(0, crop_size)\r\n","    crop_size_y1 = np.random.randint(0, crop_size)\r\n","    crop_size_y2 = np.random.randint(0, crop_size)\r\n","    angle_gen = np.random.randint(-angle, angle)\r\n","    flip_h = np.random.random()\r\n","\r\n","\r\n","    batch_images = []\r\n","    for b in range(batch_size):\r\n","      batch_images.append(process_image(data[index], (crop_size_x1, crop_size_x2, crop_size_y1, crop_size_y2), angle_gen, segment = segment, normalize = normalize, flip_h = flip_h))\r\n","      index += 1\r\n","      if index >= data.shape[0]:\r\n","        index = 0\r\n","    yield np.array(batch_images)\r\n","\r\n","def combined_generator(gen1, gen2):\r\n","  while True:\r\n","    yield next(gen1), next(gen2)\r\n","\r\n","input_generator = image_generator(xTrain)\r\n","target_generator = image_generator(yTrain, normalize = False)\r\n","train_generator = zip(input_generator, target_generator)\r\n","\r\n","input_generator_val = image_generator(xVal)\r\n","target_generator_val = image_generator(yVal, normalize = False)\r\n","val_generator = zip(input_generator_val, target_generator_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"zER_kpN80KCe","executionInfo":{"status":"ok","timestamp":1613151796363,"user_tz":-180,"elapsed":1978,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"4daeb019-2789-49a0-d8a9-e0d6b788b0c0"},"source":["plt.imshow(next(input_generator)[0])\r\n","plt.show()\r\n","plt.imshow(np.argmax(next(target_generator)[0], axis = -1))\r\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"eg42wHw3aBXL"},"source":["## Модели"]},{"cell_type":"code","metadata":{"id":"f6W-lqDtKTzB"},"source":["def fillhole(input_image):\r\n","    '''\r\n","    input gray binary image  get the filled image by floodfill method\r\n","    Note: only holes surrounded in the connected regions will be filled.\r\n","    :param input_image:\r\n","    :return:\r\n","    '''\r\n","    im_flood_fill = input_image.copy()\r\n","    h, w = input_image.shape[:2]\r\n","    mask = np.zeros((h + 2, w + 2), np.uint8)\r\n","    im_flood_fill = im_flood_fill.astype(\"uint8\")\r\n","    cv.floodFill(im_flood_fill, mask, (0, 0), 255)\r\n","    im_flood_fill_inv = cv.bitwise_not(im_flood_fill)\r\n","    img_out = input_image | im_flood_fill_inv\r\n","    return img_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVDD6PnZaMnq"},"source":["# Функция визуализации сегментированных изображений\n","def processImage(model, count = 1, n_classes = 2):\n","  indexes = np.random.randint(0, len(xVal), count) # Получаем count случайных индексов\n","  fig, axs = plt.subplots(3, count, figsize=(25, 15)) #Создаем полотно из n графиков\n","  for i,idx in enumerate(indexes): # Проходим по всем сгенерированным индексам\n","    predict = np.array(model.predict(xVal[idx].reshape(1, img_width, img_height, 3))) # Предиктим картику\n","    pr = predict[0] # Берем нулевой элемент из перидкта\n","    pr1 = [] # Пустой лист под сегментированную картинку из predicta\n","    pr2 = [] # Пустой лист под сегменитрованную картинку из yVal\n","    pr = pr.reshape(-1, n_classes) # Решейпим предикт\n","    yr = yVal[idx].reshape(-1, n_classes) # Решейпим yVal\n","    for k in range(len(pr)): # Проходим по всем уровням (количесвто классов)\n","      pr1.append(index2color(pr[k])) # Переводим индекс в писксель\n","      pr2.append(index2color(yr[k])) # Переводим индекс в писксель\n","    pr1 = np.array(pr1) # Преобразуем в numpy\n","    pr1 = pr1.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n","    pr2 = np.array(pr2) # Преобразуем в numpy\n","    pr2 = pr2.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n","    img = Image.fromarray(pr1.astype('uint8')) # Получаем картику из предикта\n","    \n","    axs[0,i].imshow(img.convert('RGBA')) # Отображаем на графике в первой линии\n","    axs[0,i].axis('off')\n","    axs[1,i].imshow(Image.fromarray(pr2.astype('uint8'))) # Отображаем на графике во второй линии сегментированное изображение из yVal\n","    axs[1,i].axis('off')\n","    axs[2,i].imshow(Image.fromarray(xVal[idx].astype('uint8'))) # Отображаем на графике в третьей линии оригинальное изображение        \n","    axs[2,i].axis('off')\n","  plt.show()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-FC9VX4zsnJa"},"source":["### U-net"]},{"cell_type":"code","metadata":{"id":"Iz9NJZsW6Eua"},"source":["'''\n","  Собственная функция метрики, обрабатывающая пересечение двух областей\n","'''\n","def dice_coef(y_true, y_pred):\n","    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.) # Возвращаем площадь пересечения деленную на площадь объединения двух областей"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-n-ivxFLKOF"},"source":["# '''\n","#   Функция создания сети\n","#     Входные параметры:\n","#     - num_classes - количество классов\n","#     - input_shape - размерность карты сегментации\n","# '''\n","# def unet(num_classes = num_classes, input_shape= (img_width, img_height, 3)):\n","#     img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n","\n","#     # Block 1\n","#     x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n","\n","#     x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n","\n","#     # Block 2\n","#     x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n","\n","#     x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n","\n","#     # Block 3\n","#     x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     block_3_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_3_out\n","\n","#     x = MaxPooling2D()(block_3_out)                                        # Добавляем слой MaxPooling2D\n","\n","#     # Block 4\n","#     x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)        # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     block_4_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_4_out\n","#     x = block_4_out \n","\n","#     # UP 2\n","#     x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 256 нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_3_out])                                      # Объединем текущий слой со слоем block_3_out\n","#     x = Conv2D(256, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 256 нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(256, (3, 3), padding='same')(x)\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     # UP 3\n","#     x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 128 нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_2_out])                                      # Объединем текущий слой со слоем block_2_out\n","#     x = Conv2D(128, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 128 нейронами\n","#     x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","#     x = Conv2D(128, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 128 нейронами\n","#     x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x) # Добавляем слой Activation\n","\n","#     # UP 4\n","#     x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n","#     x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x) # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_1_out])  # Объединем текущий слой со слоем block_1_out\n","#     x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","#     x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x) # Добавляем слой Activation\n","\n","#     x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","#     x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","#     x = Activation('relu')(x) # Добавляем слой Activation\n","\n","#     x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","#     model = Model(img_input, x) # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","#     # Компилируем модель \n","#     model.compile(optimizer=Adam(learning_rate=0.0005),\n","#                   loss='categorical_crossentropy',\n","#                   metrics=[dice_coef])\n","    \n","#     return model # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiX04rSrLMd1"},"source":["# modelUnet = unet(num_classes, (img_width, img_height, 3)) # Создаем модель unet\r\n","# #modelUnet.load_weights('/content/drive/My Drive/segmentation/weightsU/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhtO3SRyCkka"},"source":["# modelUnet.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8QIEvrI9PM1"},"source":["# from tensorflow.keras.callbacks import ModelCheckpoint\r\n","# cb = ModelCheckpoint(\r\n","#     '/content/drive/My Drive/segmentation/weightsU/',\r\n","#     monitor=\"val_loss\",\r\n","#     verbose=1,\r\n","#     save_best_only=True,\r\n","#     save_weights_only=True,\r\n","#     mode=\"min\",\r\n","#     save_freq=\"epoch\",\r\n","#     options=None\r\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFlktpNPRtVC"},"source":["# history = modelUnet.fit(xTrain, yTrain, epochs=40, batch_size=4, validation_data = (xVal, yVal), callbacks=[cb]) # Обучаем модель на выборке по трем классам"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAFRc5E32QAn"},"source":["# #modelUnet.save_weights('/content/drive/My Drive/segmentation/modelUnet.h5')\r\n","\r\n","# modelUnet = unet(num_classes, (img_width, img_height, 3)) # Создаем модель unet\r\n","# modelUnet.load_weights('/content/drive/My Drive/segmentation/weightsU/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VaAiNqnDsxgf"},"source":["#### Распознавание"]},{"cell_type":"code","metadata":{"id":"OFH24rn-noem"},"source":["# predictions = modelUnet.predict(xVal)\r\n","\r\n","# for i, pred_image in enumerate(predictions):\r\n","#   actual_image = xVal[i]\r\n","#   pred = index2color(pred_image, actual_image).astype(np.uint8)\r\n","#   pred = Image.fromarray(pred)\r\n","#   pred.save(directory + f\"predicted/simple_UNET/дог{i}.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NHDbEEibA6uf"},"source":["### Расширенная U-net"]},{"cell_type":"code","metadata":{"id":"QOjFjIERBFId"},"source":["# '''\n","#   Функция создания сети\n","#     Входные параметры:\n","#     - num_classes - количество классов\n","#     - input_shape - размерность карты сегментации\n","# '''\n","# def unetWithMask(num_classes = num_classes, input_shape = (img_width, img_height, 3)):\n","#     img_input = Input(input_shape)                                      # Создаем входной слой с размерностью input_shape\n","\n","#     # Block 1\n","#     x = Conv2D(16, (9, 9), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(16, (9, 9), padding='same', name='block1_conv2')(x)      # Добавляем Conv2D-слой с 64-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     block_1_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_1_out\n","    \n","#     block_1_out_mask = Conv2D(16, (1, 1), padding='same', activation = 'elu')(block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n","\n","#     x = Conv2D(32, (8, 8), strides = (2, 2), padding = 'same', activation = 'elu')(block_1_out) # Добавляем слой MaxPooling2D\n","\n","#     # Block 2\n","#     x = Conv2D(32, (8, 8), padding='same', name='block2_conv1')(x)     # Добавляем Conv2D-слой с 128-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x) # Добавляем слой Activation\n","\n","#     x = Conv2D(32, (8, 8), padding='same', name='block2_conv2')(x)     # Добавляем Conv2D-слой с 128-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     block_2_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_2_out\n","\n","#     block_2_out_mask = Conv2D(32, (1, 1), padding='same', activation = 'elu')(block_2_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_2_out_mask\n","    \n","#     x = Conv2D(64, (7, 7), strides = (2, 2), padding = 'same', activation = 'elu')(block_2_out)                                     # Добавляем слой MaxPooling2D\n","\n","#     # Block 3\n","#     x = Conv2D(64, (7, 7), padding='same', name='block3_conv1')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(64, (7, 7), padding='same', name='block3_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(64, (7, 7), padding='same', name='block3_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     block_3_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_3_out\n","\n","#     block_3_out_mask = Conv2D(64, (1, 1), padding='same', activation = 'elu')(block_3_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_3_out_mask\n","        \n","#     x = Conv2D(96, (6, 6), strides = (2, 2), padding = 'same', activation = 'elu')(block_3_out)                                     # Добавляем слой MaxPooling2D\n","\n","#      # Block 4\n","#     x = Conv2D(96, (6, 6), padding='same', name='block4_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(96, (6, 6), padding='same', name='block4_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(96, (6, 6), padding='same', name='block4_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     block_4_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_4_out\n","\n","#     block_4_out_mask = Conv2D(96, (1, 1), padding='same', activation = 'elu')(block_4_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_4_out_mask\n","            \n","#     x = Conv2D(128, (5, 5), strides = (2, 2), padding = 'same', activation = 'elu')(block_4_out)                                     # Добавляем слой MaxPooling2D\n","\n","#     # Block 5\n","#     x = Conv2D(128, (5, 5), padding='same', name='block5_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(128, (5, 5), padding='same', name='block5_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(128, (5, 5), padding='same', name='block5_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     block_5_out = Activation('elu')(x)                                 # Добавляем слой Activation\n","\n","#     block_5_out_mask = Conv2D(128, (1, 1), padding='same', activation = 'elu')(block_5_out)\n","\n","#     x = Conv2D(148, (4, 4), strides = (2, 2), padding = 'same', activation = 'elu')(block_5_out)\n","\n","#     #Block 6\n","#     x = Conv2D(148, (4, 4), padding='same', name='block6_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(148, (4, 4), padding='same', name='block6_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(148, (4, 4), padding='same', name='block6_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     block_6_out = Activation('elu')(x)                                 # Добавляем слой Activation\n","\n","#     block_6_out_mask = Conv2D(148, (1, 1), padding='same', activation = 'elu')(block_6_out)\n","\n","#     x = Conv2D(192, (4, 4), strides = (2, 2), padding = 'same', activation = 'elu')(block_6_out)\n","\n","#     #Block 7\n","#     x = Conv2D(192, (3, 3), padding='same', name='block7_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(192, (3, 3), padding='same', name='block7_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(192, (3, 3), padding='same', name='block7_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     block_7_out = Activation('elu')(x)                                 # Добавляем слой Activation\n","\n","#     block_7_out_mask = Conv2D(192, (1, 1), padding='same', activation = 'elu')(block_7_out)\n","\n","#     x = Conv2D(256, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_7_out)\n","\n","#     #Block 8\n","#     x = Conv2D(256, (3, 3), padding='same', name='block8_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(256, (3, 3), padding='same', name='block8_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(256, (3, 3), padding='same', name='block8_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)\n","#     x = Conv2D(256, (1, 1), padding='same')(x)\n","\n","\n","#     # UP 1\n","#     x = Conv2DTranspose(192, (3, 3), strides=(2, 2), padding='same')(x)\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_7_out, block_7_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n","#     x = Conv2D(192, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(192, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)    \n","    \n","\n","#     # UP 2\n","#     x = Conv2DTranspose(148, (4, 4), strides=(2, 2), padding='same')(x)\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_6_out, block_6_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n","#     x = Conv2D(148, (4, 4), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(148, (4, 4), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)    \n","\n","#     # UP 3\n","#     x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_5_out, block_5_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n","#     x = Conv2D(128, (5, 5), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(128, (5, 5), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)    \n","    \n"," \n","#     # UP 4\n","#     x = Conv2DTranspose(96, (6, 6), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_4_out, block_4_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n","#     x = Conv2D(96, (6, 6), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(96, (6, 6), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     # UP 5\n","#     x = Conv2DTranspose(64, (7, 7), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 256 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_3_out, block_3_out_mask])                 # Объединем текущий слой со слоем block_3_out и слоем-маской block_3_out_mask\n","#     x = Conv2D(64, (7, 7), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(64, (7, 7), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     # UP 6\n","#     x = Conv2DTranspose(32, (8, 8), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 128 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_2_out, block_2_out_mask])                 # Объединем текущий слой со слоем block_2_out и слоем-маской block_2_out_mask\n","#     x = Conv2D(32, (8, 8), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     x = Conv2D(32, (8, 8), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\n","\n","#     # UP 7\n","#     x = Conv2DTranspose(16, (9, 9), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\n","\n","#     x = concatenate([x, block_1_out, block_1_out_mask])                # Объединем текущий слой со слоем block_1_out и слоем-маской block_1_out_mask\n","#     x = Conv2D(16, (9, 9), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\n","\n","#     x = Conv2D(16, (9, 9), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n","#     inputmask = Conv2D(16, (9, 9), activation = 'elu', padding='same')(img_input)\n","#     x = Concatenate()([x, inputmask])\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\n","\n","#     x = Conv2D(num_classes, (9, 9), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","#     model = Model(img_input, x)                                        # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","#     # Компилируем модель \n","#     model.compile(optimizer=Adam(lr = 0.0001),\n","#                   loss='categorical_crossentropy',\n","#                   metrics=[dice_coef])\n","    \n","#     return model                                                       # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jegmvYcOMC1e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613163087382,"user_tz":-180,"elapsed":1411,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"9f36beb8-5d3c-48da-e40c-00262adfc0f4"},"source":["modelM3 = unetWithMask(num_classes, (img_width, img_height, 3))\r\n","modelM3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 768, 512, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 768, 512, 16) 3904        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_129 (BatchN (None, 768, 512, 16) 64          block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_129 (Activation)     (None, 768, 512, 16) 0           batch_normalization_129[0][0]    \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 768, 512, 16) 20752       activation_129[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_130 (BatchN (None, 768, 512, 16) 64          block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_130 (Activation)     (None, 768, 512, 16) 0           batch_normalization_130[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 384, 256, 32) 32800       activation_130[0][0]             \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, 384, 256, 32) 65568       conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_131 (BatchN (None, 384, 256, 32) 128         block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_131 (Activation)     (None, 384, 256, 32) 0           batch_normalization_131[0][0]    \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, 384, 256, 32) 65568       activation_131[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_132 (BatchN (None, 384, 256, 32) 128         block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_132 (Activation)     (None, 384, 256, 32) 0           batch_normalization_132[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 192, 128, 64) 100416      activation_132[0][0]             \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, 192, 128, 64) 200768      conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_133 (BatchN (None, 192, 128, 64) 256         block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_133 (Activation)     (None, 192, 128, 64) 0           batch_normalization_133[0][0]    \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, 192, 128, 64) 200768      activation_133[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_134 (BatchN (None, 192, 128, 64) 256         block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_134 (Activation)     (None, 192, 128, 64) 0           batch_normalization_134[0][0]    \n","__________________________________________________________________________________________________\n","block3_conv3 (Conv2D)           (None, 192, 128, 64) 200768      activation_134[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_135 (BatchN (None, 192, 128, 64) 256         block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","activation_135 (Activation)     (None, 192, 128, 64) 0           batch_normalization_135[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 96, 64, 96)   221280      activation_135[0][0]             \n","__________________________________________________________________________________________________\n","block4_conv1 (Conv2D)           (None, 96, 64, 96)   331872      conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_136 (BatchN (None, 96, 64, 96)   384         block4_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_136 (Activation)     (None, 96, 64, 96)   0           batch_normalization_136[0][0]    \n","__________________________________________________________________________________________________\n","block4_conv2 (Conv2D)           (None, 96, 64, 96)   331872      activation_136[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_137 (BatchN (None, 96, 64, 96)   384         block4_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_137 (Activation)     (None, 96, 64, 96)   0           batch_normalization_137[0][0]    \n","__________________________________________________________________________________________________\n","block4_conv3 (Conv2D)           (None, 96, 64, 96)   331872      activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_138 (BatchN (None, 96, 64, 96)   384         block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","activation_138 (Activation)     (None, 96, 64, 96)   0           batch_normalization_138[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 48, 32, 128)  307328      activation_138[0][0]             \n","__________________________________________________________________________________________________\n","block5_conv1 (Conv2D)           (None, 48, 32, 128)  409728      conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_139 (BatchN (None, 48, 32, 128)  512         block5_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_139 (Activation)     (None, 48, 32, 128)  0           batch_normalization_139[0][0]    \n","__________________________________________________________________________________________________\n","block5_conv2 (Conv2D)           (None, 48, 32, 128)  409728      activation_139[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_140 (BatchN (None, 48, 32, 128)  512         block5_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_140 (Activation)     (None, 48, 32, 128)  0           batch_normalization_140[0][0]    \n","__________________________________________________________________________________________________\n","block5_conv3 (Conv2D)           (None, 48, 32, 128)  409728      activation_140[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_141 (BatchN (None, 48, 32, 128)  512         block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","activation_141 (Activation)     (None, 48, 32, 128)  0           batch_normalization_141[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 24, 16, 148)  303252      activation_141[0][0]             \n","__________________________________________________________________________________________________\n","block6_conv1 (Conv2D)           (None, 24, 16, 148)  350612      conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_142 (BatchN (None, 24, 16, 148)  592         block6_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_142 (Activation)     (None, 24, 16, 148)  0           batch_normalization_142[0][0]    \n","__________________________________________________________________________________________________\n","block6_conv2 (Conv2D)           (None, 24, 16, 148)  350612      activation_142[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_143 (BatchN (None, 24, 16, 148)  592         block6_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_143 (Activation)     (None, 24, 16, 148)  0           batch_normalization_143[0][0]    \n","__________________________________________________________________________________________________\n","block6_conv3 (Conv2D)           (None, 24, 16, 148)  350612      activation_143[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_144 (BatchN (None, 24, 16, 148)  592         block6_conv3[0][0]               \n","__________________________________________________________________________________________________\n","activation_144 (Activation)     (None, 24, 16, 148)  0           batch_normalization_144[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 12, 8, 192)   454848      activation_144[0][0]             \n","__________________________________________________________________________________________________\n","block7_conv1 (Conv2D)           (None, 12, 8, 192)   331968      conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_145 (BatchN (None, 12, 8, 192)   768         block7_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_145 (Activation)     (None, 12, 8, 192)   0           batch_normalization_145[0][0]    \n","__________________________________________________________________________________________________\n","block7_conv2 (Conv2D)           (None, 12, 8, 192)   331968      activation_145[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_146 (BatchN (None, 12, 8, 192)   768         block7_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_146 (Activation)     (None, 12, 8, 192)   0           batch_normalization_146[0][0]    \n","__________________________________________________________________________________________________\n","block7_conv3 (Conv2D)           (None, 12, 8, 192)   331968      activation_146[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_147 (BatchN (None, 12, 8, 192)   768         block7_conv3[0][0]               \n","__________________________________________________________________________________________________\n","activation_147 (Activation)     (None, 12, 8, 192)   0           batch_normalization_147[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 6, 4, 256)    442624      activation_147[0][0]             \n","__________________________________________________________________________________________________\n","block8_conv1 (Conv2D)           (None, 6, 4, 256)    590080      conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_148 (BatchN (None, 6, 4, 256)    1024        block8_conv1[0][0]               \n","__________________________________________________________________________________________________\n","activation_148 (Activation)     (None, 6, 4, 256)    0           batch_normalization_148[0][0]    \n","__________________________________________________________________________________________________\n","block8_conv2 (Conv2D)           (None, 6, 4, 256)    590080      activation_148[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_149 (BatchN (None, 6, 4, 256)    1024        block8_conv2[0][0]               \n","__________________________________________________________________________________________________\n","activation_149 (Activation)     (None, 6, 4, 256)    0           batch_normalization_149[0][0]    \n","__________________________________________________________________________________________________\n","block8_conv3 (Conv2D)           (None, 6, 4, 256)    590080      activation_149[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_150 (BatchN (None, 6, 4, 256)    1024        block8_conv3[0][0]               \n","__________________________________________________________________________________________________\n","activation_150 (Activation)     (None, 6, 4, 256)    0           batch_normalization_150[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 6, 4, 256)    65792       activation_150[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_transpose_21 (Conv2DTran (None, 12, 8, 192)   442560      conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_151 (BatchN (None, 12, 8, 192)   768         conv2d_transpose_21[0][0]        \n","__________________________________________________________________________________________________\n","activation_151 (Activation)     (None, 12, 8, 192)   0           batch_normalization_151[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 12, 8, 192)   37056       activation_147[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_24 (Concatenate)    (None, 12, 8, 576)   0           activation_151[0][0]             \n","                                                                 activation_147[0][0]             \n","                                                                 conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_107 (Conv2D)             (None, 12, 8, 192)   995520      concatenate_24[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_152 (BatchN (None, 12, 8, 192)   768         conv2d_107[0][0]                 \n","__________________________________________________________________________________________________\n","activation_152 (Activation)     (None, 12, 8, 192)   0           batch_normalization_152[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_108 (Conv2D)             (None, 12, 8, 192)   331968      activation_152[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_153 (BatchN (None, 12, 8, 192)   768         conv2d_108[0][0]                 \n","__________________________________________________________________________________________________\n","activation_153 (Activation)     (None, 12, 8, 192)   0           batch_normalization_153[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_transpose_22 (Conv2DTran (None, 24, 16, 148)  454804      activation_153[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_154 (BatchN (None, 24, 16, 148)  592         conv2d_transpose_22[0][0]        \n","__________________________________________________________________________________________________\n","activation_154 (Activation)     (None, 24, 16, 148)  0           batch_normalization_154[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 24, 16, 148)  22052       activation_144[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_25 (Concatenate)    (None, 24, 16, 444)  0           activation_154[0][0]             \n","                                                                 activation_144[0][0]             \n","                                                                 conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_109 (Conv2D)             (None, 24, 16, 148)  1051540     concatenate_25[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_155 (BatchN (None, 24, 16, 148)  592         conv2d_109[0][0]                 \n","__________________________________________________________________________________________________\n","activation_155 (Activation)     (None, 24, 16, 148)  0           batch_normalization_155[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_110 (Conv2D)             (None, 24, 16, 148)  350612      activation_155[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_156 (BatchN (None, 24, 16, 148)  592         conv2d_110[0][0]                 \n","__________________________________________________________________________________________________\n","activation_156 (Activation)     (None, 24, 16, 148)  0           batch_normalization_156[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_transpose_23 (Conv2DTran (None, 48, 32, 128)  473728      activation_156[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_157 (BatchN (None, 48, 32, 128)  512         conv2d_transpose_23[0][0]        \n","__________________________________________________________________________________________________\n","activation_157 (Activation)     (None, 48, 32, 128)  0           batch_normalization_157[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 48, 32, 128)  16512       activation_141[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_26 (Concatenate)    (None, 48, 32, 384)  0           activation_157[0][0]             \n","                                                                 activation_141[0][0]             \n","                                                                 conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_111 (Conv2D)             (None, 48, 32, 128)  1228928     concatenate_26[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_158 (BatchN (None, 48, 32, 128)  512         conv2d_111[0][0]                 \n","__________________________________________________________________________________________________\n","activation_158 (Activation)     (None, 48, 32, 128)  0           batch_normalization_158[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_112 (Conv2D)             (None, 48, 32, 128)  409728      activation_158[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_159 (BatchN (None, 48, 32, 128)  512         conv2d_112[0][0]                 \n","__________________________________________________________________________________________________\n","activation_159 (Activation)     (None, 48, 32, 128)  0           batch_normalization_159[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_transpose_24 (Conv2DTran (None, 96, 64, 96)   442464      activation_159[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_160 (BatchN (None, 96, 64, 96)   384         conv2d_transpose_24[0][0]        \n","__________________________________________________________________________________________________\n","activation_160 (Activation)     (None, 96, 64, 96)   0           batch_normalization_160[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 96, 64, 96)   9312        activation_138[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_27 (Concatenate)    (None, 96, 64, 288)  0           activation_160[0][0]             \n","                                                                 activation_138[0][0]             \n","                                                                 conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_113 (Conv2D)             (None, 96, 64, 96)   995424      concatenate_27[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_161 (BatchN (None, 96, 64, 96)   384         conv2d_113[0][0]                 \n","__________________________________________________________________________________________________\n","activation_161 (Activation)     (None, 96, 64, 96)   0           batch_normalization_161[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_114 (Conv2D)             (None, 96, 64, 96)   331872      activation_161[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_162 (BatchN (None, 96, 64, 96)   384         conv2d_114[0][0]                 \n","__________________________________________________________________________________________________\n","activation_162 (Activation)     (None, 96, 64, 96)   0           batch_normalization_162[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_transpose_25 (Conv2DTran (None, 192, 128, 64) 301120      activation_162[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_163 (BatchN (None, 192, 128, 64) 256         conv2d_transpose_25[0][0]        \n","__________________________________________________________________________________________________\n","activation_163 (Activation)     (None, 192, 128, 64) 0           batch_normalization_163[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 192, 128, 64) 4160        activation_135[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_28 (Concatenate)    (None, 192, 128, 192 0           activation_163[0][0]             \n","                                                                 activation_135[0][0]             \n","                                                                 conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_115 (Conv2D)             (None, 192, 128, 64) 602176      concatenate_28[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_164 (BatchN (None, 192, 128, 64) 256         conv2d_115[0][0]                 \n","__________________________________________________________________________________________________\n","activation_164 (Activation)     (None, 192, 128, 64) 0           batch_normalization_164[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_116 (Conv2D)             (None, 192, 128, 64) 200768      activation_164[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_165 (BatchN (None, 192, 128, 64) 256         conv2d_116[0][0]                 \n","__________________________________________________________________________________________________\n","activation_165 (Activation)     (None, 192, 128, 64) 0           batch_normalization_165[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_transpose_26 (Conv2DTran (None, 384, 256, 32) 131104      activation_165[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_166 (BatchN (None, 384, 256, 32) 128         conv2d_transpose_26[0][0]        \n","__________________________________________________________________________________________________\n","activation_166 (Activation)     (None, 384, 256, 32) 0           batch_normalization_166[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 384, 256, 32) 1056        activation_132[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 384, 256, 96) 0           activation_166[0][0]             \n","                                                                 activation_132[0][0]             \n","                                                                 conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_117 (Conv2D)             (None, 384, 256, 32) 196640      concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_167 (BatchN (None, 384, 256, 32) 128         conv2d_117[0][0]                 \n","__________________________________________________________________________________________________\n","activation_167 (Activation)     (None, 384, 256, 32) 0           batch_normalization_167[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_118 (Conv2D)             (None, 384, 256, 32) 65568       activation_167[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_168 (BatchN (None, 384, 256, 32) 128         conv2d_118[0][0]                 \n","__________________________________________________________________________________________________\n","activation_168 (Activation)     (None, 384, 256, 32) 0           batch_normalization_168[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_transpose_27 (Conv2DTran (None, 768, 512, 16) 41488       activation_168[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_169 (BatchN (None, 768, 512, 16) 64          conv2d_transpose_27[0][0]        \n","__________________________________________________________________________________________________\n","activation_169 (Activation)     (None, 768, 512, 16) 0           batch_normalization_169[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 768, 512, 16) 272         activation_130[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 768, 512, 48) 0           activation_169[0][0]             \n","                                                                 activation_130[0][0]             \n","                                                                 conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_119 (Conv2D)             (None, 768, 512, 16) 62224       concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_170 (BatchN (None, 768, 512, 16) 64          conv2d_119[0][0]                 \n","__________________________________________________________________________________________________\n","activation_170 (Activation)     (None, 768, 512, 16) 0           batch_normalization_170[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_120 (Conv2D)             (None, 768, 512, 16) 20752       activation_170[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_121 (Conv2D)             (None, 768, 512, 16) 3904        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 768, 512, 32) 0           conv2d_120[0][0]                 \n","                                                                 conv2d_121[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_171 (BatchN (None, 768, 512, 32) 128         concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","activation_171 (Activation)     (None, 768, 512, 32) 0           batch_normalization_171[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_122 (Conv2D)             (None, 768, 512, 2)  5186        activation_171[0][0]             \n","==================================================================================================\n","Total params: 17,978,882\n","Trainable params: 17,969,298\n","Non-trainable params: 9,584\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SXHrGrKDBwPQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613180786740,"user_tz":-180,"elapsed":1578,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"a5071677-dbd8-4abc-e3bf-07d97fd05e2f"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\r\n","cb = ModelCheckpoint(\r\n","    '/content/drive/My Drive/segmentation/weightsUS/',\r\n","    monitor=\"val_loss\",\r\n","    verbose=1,\r\n","    save_best_only=True,\r\n","    save_weights_only=True,\r\n","    mode=\"min\",\r\n","    save_freq=\"epoch\",\r\n","    options=None\r\n",")\r\n","\r\n","\r\n","#modelM3 = load_model('/content/drive/My Drive/segmentation/weightsUS/model100M_backup.h5')\r\n","modelM3.compile(optimizer=Adam(lr = 0.00001), loss='categorical_crossentropy', metrics=[dice_coef])\r\n","#history = modelM3.fit(xTrain/255, yTrain, epochs=100, batch_size = 2, validation_data = (xVal/255, yVal), callbacks = [cb]) #  Обучаем модель на выборке по трем классам на полноразмерных изображениях\r\n","history = modelM3.fit(train_generator, steps_per_epoch=50, epochs=200, validation_data = (xVal/255, yVal), batch_size = 2, callbacks = [cb]) #  Обучаем модель на выборке по трем классам на полноразмерных изображениях"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","50/50 [==============================] - 31s 544ms/step - loss: 0.0855 - dice_coef: 0.9264 - val_loss: 0.1500 - val_dice_coef: 0.9047\n","\n","Epoch 00001: val_loss improved from inf to 0.15004, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 2/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0659 - dice_coef: 0.9345 - val_loss: 0.1506 - val_dice_coef: 0.9080\n","\n","Epoch 00002: val_loss did not improve from 0.15004\n","Epoch 3/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0877 - dice_coef: 0.9263 - val_loss: 0.1520 - val_dice_coef: 0.9075\n","\n","Epoch 00003: val_loss did not improve from 0.15004\n","Epoch 4/200\n","50/50 [==============================] - 26s 528ms/step - loss: 0.0674 - dice_coef: 0.9389 - val_loss: 0.1485 - val_dice_coef: 0.9111\n","\n","Epoch 00004: val_loss improved from 0.15004 to 0.14853, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 5/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0889 - dice_coef: 0.9305 - val_loss: 0.1453 - val_dice_coef: 0.9128\n","\n","Epoch 00005: val_loss improved from 0.14853 to 0.14528, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 6/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0728 - dice_coef: 0.9365 - val_loss: 0.1484 - val_dice_coef: 0.9112\n","\n","Epoch 00006: val_loss did not improve from 0.14528\n","Epoch 7/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0787 - dice_coef: 0.9343 - val_loss: 0.1428 - val_dice_coef: 0.9149\n","\n","Epoch 00007: val_loss improved from 0.14528 to 0.14275, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 8/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0643 - dice_coef: 0.9432 - val_loss: 0.1435 - val_dice_coef: 0.9146\n","\n","Epoch 00008: val_loss did not improve from 0.14275\n","Epoch 9/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0826 - dice_coef: 0.9326 - val_loss: 0.1451 - val_dice_coef: 0.9152\n","\n","Epoch 00009: val_loss did not improve from 0.14275\n","Epoch 10/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0634 - dice_coef: 0.9365 - val_loss: 0.1483 - val_dice_coef: 0.9129\n","\n","Epoch 00010: val_loss did not improve from 0.14275\n","Epoch 11/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0744 - dice_coef: 0.9375 - val_loss: 0.1424 - val_dice_coef: 0.9136\n","\n","Epoch 00011: val_loss improved from 0.14275 to 0.14237, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 12/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0678 - dice_coef: 0.9423 - val_loss: 0.1430 - val_dice_coef: 0.9157\n","\n","Epoch 00012: val_loss did not improve from 0.14237\n","Epoch 13/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0673 - dice_coef: 0.9429 - val_loss: 0.1497 - val_dice_coef: 0.9142\n","\n","Epoch 00013: val_loss did not improve from 0.14237\n","Epoch 14/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0668 - dice_coef: 0.9376 - val_loss: 0.1558 - val_dice_coef: 0.9116\n","\n","Epoch 00014: val_loss did not improve from 0.14237\n","Epoch 15/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0600 - dice_coef: 0.9422 - val_loss: 0.1507 - val_dice_coef: 0.9142\n","\n","Epoch 00015: val_loss did not improve from 0.14237\n","Epoch 16/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0656 - dice_coef: 0.9435 - val_loss: 0.1469 - val_dice_coef: 0.9158\n","\n","Epoch 00016: val_loss did not improve from 0.14237\n","Epoch 17/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0723 - dice_coef: 0.9415 - val_loss: 0.1451 - val_dice_coef: 0.9148\n","\n","Epoch 00017: val_loss did not improve from 0.14237\n","Epoch 18/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0697 - dice_coef: 0.9368 - val_loss: 0.1454 - val_dice_coef: 0.9151\n","\n","Epoch 00018: val_loss did not improve from 0.14237\n","Epoch 19/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0674 - dice_coef: 0.9405 - val_loss: 0.1461 - val_dice_coef: 0.9147\n","\n","Epoch 00019: val_loss did not improve from 0.14237\n","Epoch 20/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0727 - dice_coef: 0.9369 - val_loss: 0.1457 - val_dice_coef: 0.9166\n","\n","Epoch 00020: val_loss did not improve from 0.14237\n","Epoch 21/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0691 - dice_coef: 0.9406 - val_loss: 0.1473 - val_dice_coef: 0.9161\n","\n","Epoch 00021: val_loss did not improve from 0.14237\n","Epoch 22/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0911 - dice_coef: 0.9294 - val_loss: 0.1453 - val_dice_coef: 0.9153\n","\n","Epoch 00022: val_loss did not improve from 0.14237\n","Epoch 23/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0696 - dice_coef: 0.9415 - val_loss: 0.1496 - val_dice_coef: 0.9126\n","\n","Epoch 00023: val_loss did not improve from 0.14237\n","Epoch 24/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0811 - dice_coef: 0.9355 - val_loss: 0.1469 - val_dice_coef: 0.9134\n","\n","Epoch 00024: val_loss did not improve from 0.14237\n","Epoch 25/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0678 - dice_coef: 0.9406 - val_loss: 0.1530 - val_dice_coef: 0.9110\n","\n","Epoch 00025: val_loss did not improve from 0.14237\n","Epoch 26/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0786 - dice_coef: 0.9361 - val_loss: 0.1499 - val_dice_coef: 0.9111\n","\n","Epoch 00026: val_loss did not improve from 0.14237\n","Epoch 27/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0651 - dice_coef: 0.9377 - val_loss: 0.1536 - val_dice_coef: 0.9119\n","\n","Epoch 00027: val_loss did not improve from 0.14237\n","Epoch 28/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0746 - dice_coef: 0.9362 - val_loss: 0.1494 - val_dice_coef: 0.9132\n","\n","Epoch 00028: val_loss did not improve from 0.14237\n","Epoch 29/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0614 - dice_coef: 0.9430 - val_loss: 0.1517 - val_dice_coef: 0.9125\n","\n","Epoch 00029: val_loss did not improve from 0.14237\n","Epoch 30/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0734 - dice_coef: 0.9375 - val_loss: 0.1501 - val_dice_coef: 0.9137\n","\n","Epoch 00030: val_loss did not improve from 0.14237\n","Epoch 31/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0690 - dice_coef: 0.9408 - val_loss: 0.1539 - val_dice_coef: 0.9115\n","\n","Epoch 00031: val_loss did not improve from 0.14237\n","Epoch 32/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0631 - dice_coef: 0.9393 - val_loss: 0.1492 - val_dice_coef: 0.9146\n","\n","Epoch 00032: val_loss did not improve from 0.14237\n","Epoch 33/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0659 - dice_coef: 0.9415 - val_loss: 0.1563 - val_dice_coef: 0.9111\n","\n","Epoch 00033: val_loss did not improve from 0.14237\n","Epoch 34/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0666 - dice_coef: 0.9403 - val_loss: 0.1528 - val_dice_coef: 0.9121\n","\n","Epoch 00034: val_loss did not improve from 0.14237\n","Epoch 35/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0672 - dice_coef: 0.9366 - val_loss: 0.1520 - val_dice_coef: 0.9122\n","\n","Epoch 00035: val_loss did not improve from 0.14237\n","Epoch 36/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0746 - dice_coef: 0.9379 - val_loss: 0.1540 - val_dice_coef: 0.9111\n","\n","Epoch 00036: val_loss did not improve from 0.14237\n","Epoch 37/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0753 - dice_coef: 0.9348 - val_loss: 0.1554 - val_dice_coef: 0.9110\n","\n","Epoch 00037: val_loss did not improve from 0.14237\n","Epoch 38/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0724 - dice_coef: 0.9378 - val_loss: 0.1538 - val_dice_coef: 0.9127\n","\n","Epoch 00038: val_loss did not improve from 0.14237\n","Epoch 39/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0944 - dice_coef: 0.9295 - val_loss: 0.1548 - val_dice_coef: 0.9109\n","\n","Epoch 00039: val_loss did not improve from 0.14237\n","Epoch 40/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0694 - dice_coef: 0.9403 - val_loss: 0.1542 - val_dice_coef: 0.9122\n","\n","Epoch 00040: val_loss did not improve from 0.14237\n","Epoch 41/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0787 - dice_coef: 0.9379 - val_loss: 0.1546 - val_dice_coef: 0.9083\n","\n","Epoch 00041: val_loss did not improve from 0.14237\n","Epoch 42/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0659 - dice_coef: 0.9424 - val_loss: 0.1559 - val_dice_coef: 0.9118\n","\n","Epoch 00042: val_loss did not improve from 0.14237\n","Epoch 43/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0713 - dice_coef: 0.9419 - val_loss: 0.1559 - val_dice_coef: 0.9089\n","\n","Epoch 00043: val_loss did not improve from 0.14237\n","Epoch 44/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0736 - dice_coef: 0.9383 - val_loss: 0.1618 - val_dice_coef: 0.9075\n","\n","Epoch 00044: val_loss did not improve from 0.14237\n","Epoch 45/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0783 - dice_coef: 0.9358 - val_loss: 0.1574 - val_dice_coef: 0.9096\n","\n","Epoch 00045: val_loss did not improve from 0.14237\n","Epoch 46/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0587 - dice_coef: 0.9449 - val_loss: 0.1616 - val_dice_coef: 0.9085\n","\n","Epoch 00046: val_loss did not improve from 0.14237\n","Epoch 47/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0697 - dice_coef: 0.9363 - val_loss: 0.1623 - val_dice_coef: 0.9087\n","\n","Epoch 00047: val_loss did not improve from 0.14237\n","Epoch 48/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0617 - dice_coef: 0.9430 - val_loss: 0.1706 - val_dice_coef: 0.9041\n","\n","Epoch 00048: val_loss did not improve from 0.14237\n","Epoch 49/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0682 - dice_coef: 0.9428 - val_loss: 0.1592 - val_dice_coef: 0.9092\n","\n","Epoch 00049: val_loss did not improve from 0.14237\n","Epoch 50/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0592 - dice_coef: 0.9462 - val_loss: 0.1595 - val_dice_coef: 0.9104\n","\n","Epoch 00050: val_loss did not improve from 0.14237\n","Epoch 51/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0656 - dice_coef: 0.9457 - val_loss: 0.1580 - val_dice_coef: 0.9114\n","\n","Epoch 00051: val_loss did not improve from 0.14237\n","Epoch 52/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0682 - dice_coef: 0.9403 - val_loss: 0.1590 - val_dice_coef: 0.9134\n","\n","Epoch 00052: val_loss did not improve from 0.14237\n","Epoch 53/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0656 - dice_coef: 0.9409 - val_loss: 0.1584 - val_dice_coef: 0.9140\n","\n","Epoch 00053: val_loss did not improve from 0.14237\n","Epoch 54/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0955 - dice_coef: 0.9200 - val_loss: 0.1640 - val_dice_coef: 0.9136\n","\n","Epoch 00054: val_loss did not improve from 0.14237\n","Epoch 55/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0691 - dice_coef: 0.9404 - val_loss: 0.1667 - val_dice_coef: 0.9116\n","\n","Epoch 00055: val_loss did not improve from 0.14237\n","Epoch 56/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0761 - dice_coef: 0.9366 - val_loss: 0.1676 - val_dice_coef: 0.9073\n","\n","Epoch 00056: val_loss did not improve from 0.14237\n","Epoch 57/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0647 - dice_coef: 0.9396 - val_loss: 0.1648 - val_dice_coef: 0.9092\n","\n","Epoch 00057: val_loss did not improve from 0.14237\n","Epoch 58/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0827 - dice_coef: 0.9340 - val_loss: 0.1602 - val_dice_coef: 0.9128\n","\n","Epoch 00058: val_loss did not improve from 0.14237\n","Epoch 59/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0693 - dice_coef: 0.9353 - val_loss: 0.1675 - val_dice_coef: 0.9095\n","\n","Epoch 00059: val_loss did not improve from 0.14237\n","Epoch 60/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0762 - dice_coef: 0.9385 - val_loss: 0.1650 - val_dice_coef: 0.9108\n","\n","Epoch 00060: val_loss did not improve from 0.14237\n","Epoch 61/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0589 - dice_coef: 0.9453 - val_loss: 0.1668 - val_dice_coef: 0.9123\n","\n","Epoch 00061: val_loss did not improve from 0.14237\n","Epoch 62/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0799 - dice_coef: 0.9338 - val_loss: 0.1630 - val_dice_coef: 0.9101\n","\n","Epoch 00062: val_loss did not improve from 0.14237\n","Epoch 63/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0622 - dice_coef: 0.9431 - val_loss: 0.1664 - val_dice_coef: 0.9099\n","\n","Epoch 00063: val_loss did not improve from 0.14237\n","Epoch 64/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0711 - dice_coef: 0.9380 - val_loss: 0.1646 - val_dice_coef: 0.9102\n","\n","Epoch 00064: val_loss did not improve from 0.14237\n","Epoch 65/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0580 - dice_coef: 0.9404 - val_loss: 0.1647 - val_dice_coef: 0.9110\n","\n","Epoch 00065: val_loss did not improve from 0.14237\n","Epoch 66/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0660 - dice_coef: 0.9413 - val_loss: 0.1604 - val_dice_coef: 0.9100\n","\n","Epoch 00066: val_loss did not improve from 0.14237\n","Epoch 67/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0617 - dice_coef: 0.9426 - val_loss: 0.1630 - val_dice_coef: 0.9092\n","\n","Epoch 00067: val_loss did not improve from 0.14237\n","Epoch 68/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0609 - dice_coef: 0.9432 - val_loss: 0.1572 - val_dice_coef: 0.9102\n","\n","Epoch 00068: val_loss did not improve from 0.14237\n","Epoch 69/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0599 - dice_coef: 0.9415 - val_loss: 0.1601 - val_dice_coef: 0.9110\n","\n","Epoch 00069: val_loss did not improve from 0.14237\n","Epoch 70/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0665 - dice_coef: 0.9410 - val_loss: 0.1588 - val_dice_coef: 0.9105\n","\n","Epoch 00070: val_loss did not improve from 0.14237\n","Epoch 71/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0660 - dice_coef: 0.9391 - val_loss: 0.1592 - val_dice_coef: 0.9103\n","\n","Epoch 00071: val_loss did not improve from 0.14237\n","Epoch 72/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0717 - dice_coef: 0.9406 - val_loss: 0.1593 - val_dice_coef: 0.9095\n","\n","Epoch 00072: val_loss did not improve from 0.14237\n","Epoch 73/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0759 - dice_coef: 0.9359 - val_loss: 0.1582 - val_dice_coef: 0.9116\n","\n","Epoch 00073: val_loss did not improve from 0.14237\n","Epoch 74/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0667 - dice_coef: 0.9402 - val_loss: 0.1579 - val_dice_coef: 0.9107\n","\n","Epoch 00074: val_loss did not improve from 0.14237\n","Epoch 75/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0858 - dice_coef: 0.9332 - val_loss: 0.1543 - val_dice_coef: 0.9115\n","\n","Epoch 00075: val_loss did not improve from 0.14237\n","Epoch 76/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0668 - dice_coef: 0.9389 - val_loss: 0.1586 - val_dice_coef: 0.9091\n","\n","Epoch 00076: val_loss did not improve from 0.14237\n","Epoch 77/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0744 - dice_coef: 0.9369 - val_loss: 0.1547 - val_dice_coef: 0.9125\n","\n","Epoch 00077: val_loss did not improve from 0.14237\n","Epoch 78/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0594 - dice_coef: 0.9446 - val_loss: 0.1582 - val_dice_coef: 0.9121\n","\n","Epoch 00078: val_loss did not improve from 0.14237\n","Epoch 79/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0720 - dice_coef: 0.9364 - val_loss: 0.1515 - val_dice_coef: 0.9147\n","\n","Epoch 00079: val_loss did not improve from 0.14237\n","Epoch 80/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0604 - dice_coef: 0.9439 - val_loss: 0.1503 - val_dice_coef: 0.9166\n","\n","Epoch 00080: val_loss did not improve from 0.14237\n","Epoch 81/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0781 - dice_coef: 0.9374 - val_loss: 0.1479 - val_dice_coef: 0.9148\n","\n","Epoch 00081: val_loss did not improve from 0.14237\n","Epoch 82/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0546 - dice_coef: 0.9442 - val_loss: 0.1499 - val_dice_coef: 0.9141\n","\n","Epoch 00082: val_loss did not improve from 0.14237\n","Epoch 83/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0656 - dice_coef: 0.9419 - val_loss: 0.1485 - val_dice_coef: 0.9137\n","\n","Epoch 00083: val_loss did not improve from 0.14237\n","Epoch 84/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0633 - dice_coef: 0.9393 - val_loss: 0.1528 - val_dice_coef: 0.9118\n","\n","Epoch 00084: val_loss did not improve from 0.14237\n","Epoch 85/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0619 - dice_coef: 0.9431 - val_loss: 0.1532 - val_dice_coef: 0.9118\n","\n","Epoch 00085: val_loss did not improve from 0.14237\n","Epoch 86/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0560 - dice_coef: 0.9435 - val_loss: 0.1611 - val_dice_coef: 0.9073\n","\n","Epoch 00086: val_loss did not improve from 0.14237\n","Epoch 87/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0646 - dice_coef: 0.9400 - val_loss: 0.1627 - val_dice_coef: 0.9081\n","\n","Epoch 00087: val_loss did not improve from 0.14237\n","Epoch 88/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0665 - dice_coef: 0.9377 - val_loss: 0.1581 - val_dice_coef: 0.9084\n","\n","Epoch 00088: val_loss did not improve from 0.14237\n","Epoch 89/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0671 - dice_coef: 0.9394 - val_loss: 0.1553 - val_dice_coef: 0.9100\n","\n","Epoch 00089: val_loss did not improve from 0.14237\n","Epoch 90/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0683 - dice_coef: 0.9361 - val_loss: 0.1492 - val_dice_coef: 0.9142\n","\n","Epoch 00090: val_loss did not improve from 0.14237\n","Epoch 91/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0641 - dice_coef: 0.9372 - val_loss: 0.1494 - val_dice_coef: 0.9129\n","\n","Epoch 00091: val_loss did not improve from 0.14237\n","Epoch 92/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0927 - dice_coef: 0.9277 - val_loss: 0.1452 - val_dice_coef: 0.9153\n","\n","Epoch 00092: val_loss did not improve from 0.14237\n","Epoch 93/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0647 - dice_coef: 0.9414 - val_loss: 0.1487 - val_dice_coef: 0.9111\n","\n","Epoch 00093: val_loss did not improve from 0.14237\n","Epoch 94/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0711 - dice_coef: 0.9341 - val_loss: 0.1446 - val_dice_coef: 0.9139\n","\n","Epoch 00094: val_loss did not improve from 0.14237\n","Epoch 95/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0632 - dice_coef: 0.9360 - val_loss: 0.1514 - val_dice_coef: 0.9115\n","\n","Epoch 00095: val_loss did not improve from 0.14237\n","Epoch 96/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0695 - dice_coef: 0.9380 - val_loss: 0.1408 - val_dice_coef: 0.9143\n","\n","Epoch 00096: val_loss improved from 0.14237 to 0.14081, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 97/200\n","50/50 [==============================] - 27s 531ms/step - loss: 0.0649 - dice_coef: 0.9373 - val_loss: 0.1467 - val_dice_coef: 0.9109\n","\n","Epoch 00097: val_loss did not improve from 0.14081\n","Epoch 98/200\n","50/50 [==============================] - 27s 538ms/step - loss: 0.0731 - dice_coef: 0.9353 - val_loss: 0.1438 - val_dice_coef: 0.9118\n","\n","Epoch 00098: val_loss did not improve from 0.14081\n","Epoch 99/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0586 - dice_coef: 0.9409 - val_loss: 0.1491 - val_dice_coef: 0.9102\n","\n","Epoch 00099: val_loss did not improve from 0.14081\n","Epoch 100/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0729 - dice_coef: 0.9389 - val_loss: 0.1463 - val_dice_coef: 0.9106\n","\n","Epoch 00100: val_loss did not improve from 0.14081\n","Epoch 101/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0586 - dice_coef: 0.9450 - val_loss: 0.1459 - val_dice_coef: 0.9120\n","\n","Epoch 00101: val_loss did not improve from 0.14081\n","Epoch 102/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0619 - dice_coef: 0.9393 - val_loss: 0.1461 - val_dice_coef: 0.9095\n","\n","Epoch 00102: val_loss did not improve from 0.14081\n","Epoch 103/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0611 - dice_coef: 0.9450 - val_loss: 0.1464 - val_dice_coef: 0.9108\n","\n","Epoch 00103: val_loss did not improve from 0.14081\n","Epoch 104/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0620 - dice_coef: 0.9435 - val_loss: 0.1404 - val_dice_coef: 0.9135\n","\n","Epoch 00104: val_loss improved from 0.14081 to 0.14038, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 105/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0642 - dice_coef: 0.9402 - val_loss: 0.1397 - val_dice_coef: 0.9158\n","\n","Epoch 00105: val_loss improved from 0.14038 to 0.13971, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 106/200\n","50/50 [==============================] - 27s 531ms/step - loss: 0.0657 - dice_coef: 0.9399 - val_loss: 0.1423 - val_dice_coef: 0.9124\n","\n","Epoch 00106: val_loss did not improve from 0.13971\n","Epoch 107/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0856 - dice_coef: 0.9229 - val_loss: 0.1454 - val_dice_coef: 0.9122\n","\n","Epoch 00107: val_loss did not improve from 0.13971\n","Epoch 108/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0615 - dice_coef: 0.9416 - val_loss: 0.1446 - val_dice_coef: 0.9105\n","\n","Epoch 00108: val_loss did not improve from 0.13971\n","Epoch 109/200\n","50/50 [==============================] - 26s 531ms/step - loss: 0.0700 - dice_coef: 0.9366 - val_loss: 0.1413 - val_dice_coef: 0.9143\n","\n","Epoch 00109: val_loss did not improve from 0.13971\n","Epoch 110/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0616 - dice_coef: 0.9392 - val_loss: 0.1429 - val_dice_coef: 0.9142\n","\n","Epoch 00110: val_loss did not improve from 0.13971\n","Epoch 111/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0716 - dice_coef: 0.9372 - val_loss: 0.1406 - val_dice_coef: 0.9163\n","\n","Epoch 00111: val_loss did not improve from 0.13971\n","Epoch 112/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0646 - dice_coef: 0.9411 - val_loss: 0.1465 - val_dice_coef: 0.9131\n","\n","Epoch 00112: val_loss did not improve from 0.13971\n","Epoch 113/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0757 - dice_coef: 0.9375 - val_loss: 0.1615 - val_dice_coef: 0.9086\n","\n","Epoch 00113: val_loss did not improve from 0.13971\n","Epoch 114/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0553 - dice_coef: 0.9425 - val_loss: 0.1559 - val_dice_coef: 0.9119\n","\n","Epoch 00114: val_loss did not improve from 0.13971\n","Epoch 115/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0713 - dice_coef: 0.9338 - val_loss: 0.1461 - val_dice_coef: 0.9151\n","\n","Epoch 00115: val_loss did not improve from 0.13971\n","Epoch 116/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0604 - dice_coef: 0.9438 - val_loss: 0.1458 - val_dice_coef: 0.9160\n","\n","Epoch 00116: val_loss did not improve from 0.13971\n","Epoch 117/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0638 - dice_coef: 0.9440 - val_loss: 0.1437 - val_dice_coef: 0.9169\n","\n","Epoch 00117: val_loss did not improve from 0.13971\n","Epoch 118/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0578 - dice_coef: 0.9429 - val_loss: 0.1441 - val_dice_coef: 0.9165\n","\n","Epoch 00118: val_loss did not improve from 0.13971\n","Epoch 119/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0618 - dice_coef: 0.9449 - val_loss: 0.1426 - val_dice_coef: 0.9156\n","\n","Epoch 00119: val_loss did not improve from 0.13971\n","Epoch 120/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0568 - dice_coef: 0.9422 - val_loss: 0.1438 - val_dice_coef: 0.9159\n","\n","Epoch 00120: val_loss did not improve from 0.13971\n","Epoch 121/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0583 - dice_coef: 0.9449 - val_loss: 0.1418 - val_dice_coef: 0.9149\n","\n","Epoch 00121: val_loss did not improve from 0.13971\n","Epoch 122/200\n","50/50 [==============================] - 26s 531ms/step - loss: 0.0579 - dice_coef: 0.9402 - val_loss: 0.1441 - val_dice_coef: 0.9131\n","\n","Epoch 00122: val_loss did not improve from 0.13971\n","Epoch 123/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0585 - dice_coef: 0.9441 - val_loss: 0.1407 - val_dice_coef: 0.9145\n","\n","Epoch 00123: val_loss did not improve from 0.13971\n","Epoch 124/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0599 - dice_coef: 0.9410 - val_loss: 0.1418 - val_dice_coef: 0.9157\n","\n","Epoch 00124: val_loss did not improve from 0.13971\n","Epoch 125/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0610 - dice_coef: 0.9386 - val_loss: 0.1477 - val_dice_coef: 0.9104\n","\n","Epoch 00125: val_loss did not improve from 0.13971\n","Epoch 126/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0672 - dice_coef: 0.9387 - val_loss: 0.1433 - val_dice_coef: 0.9157\n","\n","Epoch 00126: val_loss did not improve from 0.13971\n","Epoch 127/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0650 - dice_coef: 0.9414 - val_loss: 0.1461 - val_dice_coef: 0.9127\n","\n","Epoch 00127: val_loss did not improve from 0.13971\n","Epoch 128/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0766 - dice_coef: 0.9361 - val_loss: 0.1396 - val_dice_coef: 0.9172\n","\n","Epoch 00128: val_loss improved from 0.13971 to 0.13959, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 129/200\n","50/50 [==============================] - 27s 531ms/step - loss: 0.0614 - dice_coef: 0.9420 - val_loss: 0.1459 - val_dice_coef: 0.9137\n","\n","Epoch 00129: val_loss did not improve from 0.13959\n","Epoch 130/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0695 - dice_coef: 0.9406 - val_loss: 0.1375 - val_dice_coef: 0.9200\n","\n","Epoch 00130: val_loss improved from 0.13959 to 0.13751, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 131/200\n","50/50 [==============================] - 27s 531ms/step - loss: 0.0550 - dice_coef: 0.9457 - val_loss: 0.1417 - val_dice_coef: 0.9150\n","\n","Epoch 00131: val_loss did not improve from 0.13751\n","Epoch 132/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0646 - dice_coef: 0.9413 - val_loss: 0.1391 - val_dice_coef: 0.9153\n","\n","Epoch 00132: val_loss did not improve from 0.13751\n","Epoch 133/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0563 - dice_coef: 0.9438 - val_loss: 0.1390 - val_dice_coef: 0.9164\n","\n","Epoch 00133: val_loss did not improve from 0.13751\n","Epoch 134/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0636 - dice_coef: 0.9415 - val_loss: 0.1377 - val_dice_coef: 0.9182\n","\n","Epoch 00134: val_loss did not improve from 0.13751\n","Epoch 135/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0541 - dice_coef: 0.9404 - val_loss: 0.1410 - val_dice_coef: 0.9150\n","\n","Epoch 00135: val_loss did not improve from 0.13751\n","Epoch 136/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0630 - dice_coef: 0.9408 - val_loss: 0.1390 - val_dice_coef: 0.9163\n","\n","Epoch 00136: val_loss did not improve from 0.13751\n","Epoch 137/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0581 - dice_coef: 0.9416 - val_loss: 0.1386 - val_dice_coef: 0.9172\n","\n","Epoch 00137: val_loss did not improve from 0.13751\n","Epoch 138/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0589 - dice_coef: 0.9454 - val_loss: 0.1355 - val_dice_coef: 0.9195\n","\n","Epoch 00138: val_loss improved from 0.13751 to 0.13546, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 139/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0536 - dice_coef: 0.9462 - val_loss: 0.1381 - val_dice_coef: 0.9186\n","\n","Epoch 00139: val_loss did not improve from 0.13546\n","Epoch 140/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0627 - dice_coef: 0.9409 - val_loss: 0.1344 - val_dice_coef: 0.9179\n","\n","Epoch 00140: val_loss improved from 0.13546 to 0.13445, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 141/200\n","50/50 [==============================] - 27s 531ms/step - loss: 0.0605 - dice_coef: 0.9399 - val_loss: 0.1385 - val_dice_coef: 0.9169\n","\n","Epoch 00141: val_loss did not improve from 0.13445\n","Epoch 142/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0621 - dice_coef: 0.9470 - val_loss: 0.1382 - val_dice_coef: 0.9156\n","\n","Epoch 00142: val_loss did not improve from 0.13445\n","Epoch 143/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0623 - dice_coef: 0.9418 - val_loss: 0.1354 - val_dice_coef: 0.9200\n","\n","Epoch 00143: val_loss did not improve from 0.13445\n","Epoch 144/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0626 - dice_coef: 0.9453 - val_loss: 0.1354 - val_dice_coef: 0.9185\n","\n","Epoch 00144: val_loss did not improve from 0.13445\n","Epoch 145/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0771 - dice_coef: 0.9310 - val_loss: 0.1350 - val_dice_coef: 0.9201\n","\n","Epoch 00145: val_loss did not improve from 0.13445\n","Epoch 146/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0558 - dice_coef: 0.9446 - val_loss: 0.1377 - val_dice_coef: 0.9161\n","\n","Epoch 00146: val_loss did not improve from 0.13445\n","Epoch 147/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0632 - dice_coef: 0.9453 - val_loss: 0.1313 - val_dice_coef: 0.9213\n","\n","Epoch 00147: val_loss improved from 0.13445 to 0.13133, saving model to /content/drive/My Drive/segmentation/weightsUS/\n","Epoch 148/200\n","50/50 [==============================] - 27s 531ms/step - loss: 0.0598 - dice_coef: 0.9398 - val_loss: 0.1382 - val_dice_coef: 0.9169\n","\n","Epoch 00148: val_loss did not improve from 0.13133\n","Epoch 149/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0607 - dice_coef: 0.9440 - val_loss: 0.1360 - val_dice_coef: 0.9184\n","\n","Epoch 00149: val_loss did not improve from 0.13133\n","Epoch 150/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0618 - dice_coef: 0.9473 - val_loss: 0.1428 - val_dice_coef: 0.9148\n","\n","Epoch 00150: val_loss did not improve from 0.13133\n","Epoch 151/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0647 - dice_coef: 0.9419 - val_loss: 0.1358 - val_dice_coef: 0.9170\n","\n","Epoch 00151: val_loss did not improve from 0.13133\n","Epoch 152/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0518 - dice_coef: 0.9459 - val_loss: 0.1396 - val_dice_coef: 0.9158\n","\n","Epoch 00152: val_loss did not improve from 0.13133\n","Epoch 153/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0665 - dice_coef: 0.9386 - val_loss: 0.1349 - val_dice_coef: 0.9191\n","\n","Epoch 00153: val_loss did not improve from 0.13133\n","Epoch 154/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0518 - dice_coef: 0.9447 - val_loss: 0.1390 - val_dice_coef: 0.9173\n","\n","Epoch 00154: val_loss did not improve from 0.13133\n","Epoch 155/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0565 - dice_coef: 0.9463 - val_loss: 0.1331 - val_dice_coef: 0.9210\n","\n","Epoch 00155: val_loss did not improve from 0.13133\n","Epoch 156/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0510 - dice_coef: 0.9495 - val_loss: 0.1402 - val_dice_coef: 0.9163\n","\n","Epoch 00156: val_loss did not improve from 0.13133\n","Epoch 157/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0535 - dice_coef: 0.9424 - val_loss: 0.1359 - val_dice_coef: 0.9177\n","\n","Epoch 00157: val_loss did not improve from 0.13133\n","Epoch 158/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0567 - dice_coef: 0.9459 - val_loss: 0.1369 - val_dice_coef: 0.9185\n","\n","Epoch 00158: val_loss did not improve from 0.13133\n","Epoch 159/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0593 - dice_coef: 0.9428 - val_loss: 0.1358 - val_dice_coef: 0.9158\n","\n","Epoch 00159: val_loss did not improve from 0.13133\n","Epoch 160/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0603 - dice_coef: 0.9375 - val_loss: 0.1352 - val_dice_coef: 0.9195\n","\n","Epoch 00160: val_loss did not improve from 0.13133\n","Epoch 161/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0578 - dice_coef: 0.9430 - val_loss: 0.1400 - val_dice_coef: 0.9158\n","\n","Epoch 00161: val_loss did not improve from 0.13133\n","Epoch 162/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0657 - dice_coef: 0.9410 - val_loss: 0.1378 - val_dice_coef: 0.9210\n","\n","Epoch 00162: val_loss did not improve from 0.13133\n","Epoch 163/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0536 - dice_coef: 0.9432 - val_loss: 0.1405 - val_dice_coef: 0.9171\n","\n","Epoch 00163: val_loss did not improve from 0.13133\n","Epoch 164/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0696 - dice_coef: 0.9367 - val_loss: 0.1403 - val_dice_coef: 0.9182\n","\n","Epoch 00164: val_loss did not improve from 0.13133\n","Epoch 165/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0596 - dice_coef: 0.9458 - val_loss: 0.1428 - val_dice_coef: 0.9145\n","\n","Epoch 00165: val_loss did not improve from 0.13133\n","Epoch 166/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0590 - dice_coef: 0.9401 - val_loss: 0.1418 - val_dice_coef: 0.9182\n","\n","Epoch 00166: val_loss did not improve from 0.13133\n","Epoch 167/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0529 - dice_coef: 0.9514 - val_loss: 0.1376 - val_dice_coef: 0.9204\n","\n","Epoch 00167: val_loss did not improve from 0.13133\n","Epoch 168/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0669 - dice_coef: 0.9401 - val_loss: 0.1341 - val_dice_coef: 0.9211\n","\n","Epoch 00168: val_loss did not improve from 0.13133\n","Epoch 169/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0520 - dice_coef: 0.9496 - val_loss: 0.1420 - val_dice_coef: 0.9182\n","\n","Epoch 00169: val_loss did not improve from 0.13133\n","Epoch 170/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0578 - dice_coef: 0.9449 - val_loss: 0.1398 - val_dice_coef: 0.9188\n","\n","Epoch 00170: val_loss did not improve from 0.13133\n","Epoch 171/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0554 - dice_coef: 0.9467 - val_loss: 0.1394 - val_dice_coef: 0.9179\n","\n","Epoch 00171: val_loss did not improve from 0.13133\n","Epoch 172/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0569 - dice_coef: 0.9410 - val_loss: 0.1367 - val_dice_coef: 0.9200\n","\n","Epoch 00172: val_loss did not improve from 0.13133\n","Epoch 173/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0542 - dice_coef: 0.9480 - val_loss: 0.1481 - val_dice_coef: 0.9195\n","\n","Epoch 00173: val_loss did not improve from 0.13133\n","Epoch 174/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0539 - dice_coef: 0.9474 - val_loss: 0.1380 - val_dice_coef: 0.9207\n","\n","Epoch 00174: val_loss did not improve from 0.13133\n","Epoch 175/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0540 - dice_coef: 0.9507 - val_loss: 0.1344 - val_dice_coef: 0.9215\n","\n","Epoch 00175: val_loss did not improve from 0.13133\n","Epoch 176/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0607 - dice_coef: 0.9455 - val_loss: 0.1336 - val_dice_coef: 0.9214\n","\n","Epoch 00176: val_loss did not improve from 0.13133\n","Epoch 177/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0596 - dice_coef: 0.9429 - val_loss: 0.1356 - val_dice_coef: 0.9200\n","\n","Epoch 00177: val_loss did not improve from 0.13133\n","Epoch 178/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0564 - dice_coef: 0.9406 - val_loss: 0.1351 - val_dice_coef: 0.9186\n","\n","Epoch 00178: val_loss did not improve from 0.13133\n","Epoch 179/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0680 - dice_coef: 0.9335 - val_loss: 0.1414 - val_dice_coef: 0.9179\n","\n","Epoch 00179: val_loss did not improve from 0.13133\n","Epoch 180/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0607 - dice_coef: 0.9431 - val_loss: 0.1408 - val_dice_coef: 0.9165\n","\n","Epoch 00180: val_loss did not improve from 0.13133\n","Epoch 181/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0681 - dice_coef: 0.9394 - val_loss: 0.1406 - val_dice_coef: 0.9164\n","\n","Epoch 00181: val_loss did not improve from 0.13133\n","Epoch 182/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0618 - dice_coef: 0.9398 - val_loss: 0.1394 - val_dice_coef: 0.9146\n","\n","Epoch 00182: val_loss did not improve from 0.13133\n","Epoch 183/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0617 - dice_coef: 0.9426 - val_loss: 0.1374 - val_dice_coef: 0.9147\n","\n","Epoch 00183: val_loss did not improve from 0.13133\n","Epoch 184/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0564 - dice_coef: 0.9418 - val_loss: 0.1403 - val_dice_coef: 0.9148\n","\n","Epoch 00184: val_loss did not improve from 0.13133\n","Epoch 185/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0600 - dice_coef: 0.9409 - val_loss: 0.1366 - val_dice_coef: 0.9158\n","\n","Epoch 00185: val_loss did not improve from 0.13133\n","Epoch 186/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0564 - dice_coef: 0.9418 - val_loss: 0.1354 - val_dice_coef: 0.9180\n","\n","Epoch 00186: val_loss did not improve from 0.13133\n","Epoch 187/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0641 - dice_coef: 0.9406 - val_loss: 0.1331 - val_dice_coef: 0.9193\n","\n","Epoch 00187: val_loss did not improve from 0.13133\n","Epoch 188/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0510 - dice_coef: 0.9413 - val_loss: 0.1340 - val_dice_coef: 0.9209\n","\n","Epoch 00188: val_loss did not improve from 0.13133\n","Epoch 189/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0598 - dice_coef: 0.9419 - val_loss: 0.1340 - val_dice_coef: 0.9181\n","\n","Epoch 00189: val_loss did not improve from 0.13133\n","Epoch 190/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0556 - dice_coef: 0.9453 - val_loss: 0.1377 - val_dice_coef: 0.9162\n","\n","Epoch 00190: val_loss did not improve from 0.13133\n","Epoch 191/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0574 - dice_coef: 0.9460 - val_loss: 0.1358 - val_dice_coef: 0.9171\n","\n","Epoch 00191: val_loss did not improve from 0.13133\n","Epoch 192/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0540 - dice_coef: 0.9444 - val_loss: 0.1370 - val_dice_coef: 0.9164\n","\n","Epoch 00192: val_loss did not improve from 0.13133\n","Epoch 193/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0642 - dice_coef: 0.9418 - val_loss: 0.1386 - val_dice_coef: 0.9152\n","\n","Epoch 00193: val_loss did not improve from 0.13133\n","Epoch 194/200\n","50/50 [==============================] - 26s 529ms/step - loss: 0.0637 - dice_coef: 0.9403 - val_loss: 0.1413 - val_dice_coef: 0.9148\n","\n","Epoch 00194: val_loss did not improve from 0.13133\n","Epoch 195/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0622 - dice_coef: 0.9417 - val_loss: 0.1420 - val_dice_coef: 0.9127\n","\n","Epoch 00195: val_loss did not improve from 0.13133\n","Epoch 196/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0612 - dice_coef: 0.9460 - val_loss: 0.1386 - val_dice_coef: 0.9156\n","\n","Epoch 00196: val_loss did not improve from 0.13133\n","Epoch 197/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0589 - dice_coef: 0.9436 - val_loss: 0.1401 - val_dice_coef: 0.9140\n","\n","Epoch 00197: val_loss did not improve from 0.13133\n","Epoch 198/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0733 - dice_coef: 0.9343 - val_loss: 0.1397 - val_dice_coef: 0.9144\n","\n","Epoch 00198: val_loss did not improve from 0.13133\n","Epoch 199/200\n","50/50 [==============================] - 26s 530ms/step - loss: 0.0564 - dice_coef: 0.9443 - val_loss: 0.1446 - val_dice_coef: 0.9101\n","\n","Epoch 00199: val_loss did not improve from 0.13133\n","Epoch 200/200\n","50/50 [==============================] - 26s 531ms/step - loss: 0.0630 - dice_coef: 0.9439 - val_loss: 0.1390 - val_dice_coef: 0.9164\n","\n","Epoch 00200: val_loss did not improve from 0.13133\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zqNByTX0ACP7"},"source":["modelM3.compile(optimizer=Adam(lr = 0.00002), loss='categorical_crossentropy', metrics = ['accuracy'])\r\n","#save_model(modelM3, directory + \"weightsUS/acc09811.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0V_SvtOp__C"},"source":["#### Распознавание"]},{"cell_type":"code","metadata":{"id":"xA5zxadGqFkK"},"source":["#modelM3 = load_model('/content/drive/My Drive/segmentation/weightsUS/model100Melu.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Q9R3f9ja6D6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613170817701,"user_tz":-180,"elapsed":41704,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"d893f4b0-cb04-430f-ef9d-3f25e2a4d72c"},"source":["predictions = modelM3.predict(xVal/255, batch_size = 2)\r\n","\r\n","for i, pred_image in tqdm.tqdm(enumerate(predictions)):\r\n","  actual_image = xVal[i]\r\n","  pred = index2color(pred_image, actual_image, final_mode = True).astype(np.uint8)\r\n","  pred = Image.fromarray(pred)\r\n","  pred.save(directory + f\"predicted/final_results/дог{i}.jpg\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["24it [00:39,  1.64s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"vO8HkD95N_kZ"},"source":["# ResNet"]},{"cell_type":"code","metadata":{"id":"j_9CMU7lOB7C"},"source":["def reslayer(*args, x, n = 4, **kwargs):\r\n","  y = Conv2D(padding = 'same', *args, **kwargs)(x)\r\n","  z = y\r\n","  for i in range(n):\r\n","    y = Conv2D(padding = 'same', *args, **kwargs)(y)\r\n","    y = BatchNormalization()(y)\r\n","    y = tf.keras.layers.LeakyReLU(alpha=0.4)(y)\r\n","  try:\r\n","    y = Add()([x, y]) #Conv-Dense model\r\n","  except: y = Add()([z, y])\r\n","  return y\r\n","\r\n","def ResSimple(num_classes = num_classes, input_shape = (img_width, img_height, 3)):\r\n","  img_input = Input(input_shape)\r\n","  x = reslayer(128, (3, 3), x = img_input, n = 10)\r\n","  output = Conv2D(num_classes, (3, 3), padding = 'same', activation = 'softmax')(x)\r\n","\r\n","  resnet_model = Model(img_input, output)\r\n","  resnet_model.compile(optimizer = Adam(lr = 5e-4), loss = 'categorical_crossentropy', metrics = [dice_coef])\r\n","  return resnet_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5HELeUmZaIjM","executionInfo":{"status":"ok","timestamp":1612317940463,"user_tz":-180,"elapsed":1351,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"03498623-3765-4b91-8841-412597e768d8"},"source":["resnet_model = ResSimple()\r\n","resnet_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 512, 768, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 512, 768, 128 3584        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 512, 768, 128 147584      conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 512, 768, 128 512         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 512, 768, 128 0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 512, 768, 128 512         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 512, 768, 128 512         conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 512, 768, 128 512         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 512, 768, 128 512         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 512, 768, 128 512         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 512, 768, 128 512         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 512, 768, 128 512         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 512, 768, 128 512         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 512, 768, 128 147584      leaky_re_lu_8[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 512, 768, 128 512         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, 512, 768, 128 0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 512, 768, 128 0           conv2d_39[0][0]                  \n","                                                                 leaky_re_lu_9[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 512, 768, 2)  2306        add_1[0][0]                      \n","==================================================================================================\n","Total params: 1,486,850\n","Trainable params: 1,484,290\n","Non-trainable params: 2,560\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fy0Ru0SbZ9hO"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\r\n","cb = ModelCheckpoint(\r\n","    '/content/drive/My Drive/segmentation/weightsRes/',\r\n","    monitor=\"val_loss\",\r\n","    verbose=1,\r\n","    save_best_only=True,\r\n","    save_weights_only=True,\r\n","    mode=\"min\",\r\n","    save_freq=\"epoch\",\r\n","    options=None\r\n",")\r\n","\r\n","history = resnet_model.fit(xTrain, yTrain, epochs=20, batch_size=2, validation_data = (xVal, yVal), callbacks = [cb]) #  Обучаем модель на выборке по трем классам на полноразмерных изображениях"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7MF3vAUo7w0"},"source":["resnet_model.save_weights('/content/drive/My Drive/segmentation/weightsRes/model_resnet.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTOjLDYYpRo9"},"source":["resnet_model = ResSimple()\r\n","resnet_model.load_weights('/content/drive/My Drive/segmentation/weightsRes/model_resnet.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFcbM3qOotV1"},"source":["predictions = resnet_model.predict(xVal, batch_size = 2)\r\n","\r\n","for i, pred_image in enumerate(predictions):\r\n","  actual_image = xVal[i]\r\n","  pred = index2color(pred_image, actual_image).astype(np.uint8)\r\n","  pred = Image.fromarray(pred)\r\n","  pred.save(directory + f\"predicted/RESnet/дог{i}.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hg1kHJrEAikO"},"source":["# PSPNet"]},{"cell_type":"code","metadata":{"id":"VC6p8qHuAf-m"},"source":["def PSPNet(num_classes = num_classes, input_shape = (img_width, img_height, 3)):\r\n","    img_input = Input(input_shape)\r\n","    start = Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(img_input)\r\n","\r\n","    factor1 = 2\r\n","    factor2 = 4\r\n","    factor3 = 8\r\n","    factor4 = 16\r\n","    factor5 = 32\r\n","\r\n","    branch1 = Conv2D(32, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(start)\r\n","    branch1 = Conv2DTranspose(64, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch1)\r\n","\r\n","    branch2 = Conv2D(64, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(start)\r\n","    branch2 = Conv2D(128, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch2)\r\n","    branch2 = Conv2DTranspose(128, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch2)\r\n","    branch2 = Conv2DTranspose(64, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch2)\r\n","\r\n","    branch3 = Conv2D(64, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(start)\r\n","    branch3 = Conv2D(128, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch3)\r\n","    branch3 = Conv2D(256, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch3)\r\n","    branch3 = Conv2DTranspose(256, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch3)\r\n","    branch3 = Conv2DTranspose(128, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch3)\r\n","    branch3 = Conv2DTranspose(64, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch3)\r\n","\r\n","    branch4 = Conv2D(64, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(start)\r\n","    branch4 = Conv2D(128, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch4)\r\n","    branch4 = Conv2D(256, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch4)\r\n","    branch4 = Conv2D(512, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch4)\r\n","    branch4 = Conv2DTranspose(512, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch4)\r\n","    branch4 = Conv2DTranspose(256, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch4)\r\n","    branch4 = Conv2DTranspose(128, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch4)\r\n","    branch4 = Conv2DTranspose(64, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch4)\r\n","\r\n","    branch5 = Conv2D(64, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(start)\r\n","    branch5 = Conv2D(128, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch5)\r\n","    branch5 = Conv2D(256, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch5)\r\n","    branch5 = Conv2D(512, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch5)\r\n","    branch5 = Conv2D(768, (3, 3), strides = (2, 2), padding = 'same', activation = 'relu')(branch5)\r\n","    branch5 = Conv2DTranspose(768, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch5)\r\n","    branch5 = Conv2DTranspose(512, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch5)\r\n","    branch5 = Conv2DTranspose(256, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch5)\r\n","    branch5 = Conv2DTranspose(128, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch5)\r\n","    branch5 = Conv2DTranspose(64, (3, 3), strides = (2, 2), activation = 'relu', padding = 'same')(branch5)\r\n","\r\n","    end = concatenate([branch1, branch2, branch3, branch4, branch5])\r\n","    final = Conv2D(32, (3, 3), padding = 'same', activation = 'relu')(end)\r\n","    final_2 = Add()([start, final])\r\n","    output = Conv2D(num_classes, (3, 3), padding = 'same', activation = 'sigmoid')(final_2)\r\n","    psp_net = Model(img_input, output)\r\n","\r\n","    psp_net.compile(optimizer=Adam(lr = 0.0005),\r\n","                  loss='categorical_crossentropy',\r\n","                  metrics=[dice_coef])\r\n","    \r\n","    return psp_net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXbN2BCSJx4Z","executionInfo":{"status":"ok","timestamp":1612380079814,"user_tz":-180,"elapsed":1076,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"cbe5e0a2-6d62-46ba-ff28-0251cc0f844d"},"source":["psp_net = PSPNet()\r\n","psp_net.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, 512, 768, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 512, 768, 32) 896         input_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 256, 384, 64) 18496       conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 128, 192, 128 73856       conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 256, 384, 64) 18496       conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 64, 96, 256)  295168      conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 128, 192, 128 73856       conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 32, 48, 512)  1180160     conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 256, 384, 64) 18496       conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 64, 96, 256)  295168      conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 16, 24, 768)  3539712     conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 128, 192, 128 73856       conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 32, 48, 512)  1180160     conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_85 (Conv2DTran (None, 32, 48, 768)  5309184     conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 256, 384, 64) 18496       conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 64, 96, 256)  295168      conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_81 (Conv2DTran (None, 64, 96, 512)  2359808     conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_86 (Conv2DTran (None, 64, 96, 512)  3539456     conv2d_transpose_85[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 128, 192, 128 73856       conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_78 (Conv2DTran (None, 128, 192, 256 590080      conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_82 (Conv2DTran (None, 128, 192, 256 1179904     conv2d_transpose_81[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_transpose_87 (Conv2DTran (None, 128, 192, 256 1179904     conv2d_transpose_86[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 256, 384, 32) 9248        conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_76 (Conv2DTran (None, 256, 384, 128 147584      conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_79 (Conv2DTran (None, 256, 384, 128 295040      conv2d_transpose_78[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_transpose_83 (Conv2DTran (None, 256, 384, 128 295040      conv2d_transpose_82[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_transpose_88 (Conv2DTran (None, 256, 384, 128 295040      conv2d_transpose_87[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_transpose_75 (Conv2DTran (None, 512, 768, 64) 18496       conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_77 (Conv2DTran (None, 512, 768, 64) 73792       conv2d_transpose_76[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_transpose_80 (Conv2DTran (None, 512, 768, 64) 73792       conv2d_transpose_79[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_transpose_84 (Conv2DTran (None, 512, 768, 64) 73792       conv2d_transpose_83[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_transpose_89 (Conv2DTran (None, 512, 768, 64) 73792       conv2d_transpose_88[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 512, 768, 320 0           conv2d_transpose_75[0][0]        \n","                                                                 conv2d_transpose_77[0][0]        \n","                                                                 conv2d_transpose_80[0][0]        \n","                                                                 conv2d_transpose_84[0][0]        \n","                                                                 conv2d_transpose_89[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 512, 768, 32) 92192       concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 512, 768, 32) 0           conv2d_88[0][0]                  \n","                                                                 conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 512, 768, 2)  578         add_5[0][0]                      \n","==================================================================================================\n","Total params: 22,762,562\n","Trainable params: 22,762,562\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGge1c6KKvC8","executionInfo":{"status":"ok","timestamp":1612383156677,"user_tz":-180,"elapsed":3074233,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"7ee9dfd3-6d1d-4f0d-f0b3-c5f8d208beab"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\r\n","cb = ModelCheckpoint(\r\n","    '/content/drive/My Drive/segmentation/weightsPSP/',\r\n","    monitor=\"val_loss\",\r\n","    verbose=1,\r\n","    save_best_only=True,\r\n","    save_weights_only=True,\r\n","    mode=\"min\",\r\n","    save_freq=\"epoch\",\r\n","    options=None\r\n",")\r\n","\r\n","history = psp_net.fit(xTrain, yTrain, epochs=60, batch_size=2, validation_data = (xVal, yVal), callbacks = [cb]) #  Обучаем модель на выборке по трем классам на полноразмерных изображениях"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/60\n","112/112 [==============================] - 54s 460ms/step - loss: 4.3397 - dice_coef: 0.7121 - val_loss: 0.6488 - val_dice_coef: 0.6833\n","\n","Epoch 00001: val_loss improved from inf to 0.64884, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 2/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.6436 - dice_coef: 0.7070 - val_loss: 0.4304 - val_dice_coef: 0.6658\n","\n","Epoch 00002: val_loss improved from 0.64884 to 0.43043, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 3/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.3368 - dice_coef: 0.6897 - val_loss: 0.3713 - val_dice_coef: 0.6885\n","\n","Epoch 00003: val_loss improved from 0.43043 to 0.37127, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 4/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.4566 - dice_coef: 0.7207 - val_loss: 0.3590 - val_dice_coef: 0.6778\n","\n","Epoch 00004: val_loss improved from 0.37127 to 0.35903, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 5/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.3303 - dice_coef: 0.6810 - val_loss: 0.2851 - val_dice_coef: 0.6866\n","\n","Epoch 00005: val_loss improved from 0.35903 to 0.28509, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 6/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.2812 - dice_coef: 0.6864 - val_loss: 0.2629 - val_dice_coef: 0.6880\n","\n","Epoch 00006: val_loss improved from 0.28509 to 0.26291, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 7/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.2654 - dice_coef: 0.7007 - val_loss: 0.2435 - val_dice_coef: 0.6825\n","\n","Epoch 00007: val_loss improved from 0.26291 to 0.24354, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 8/60\n","112/112 [==============================] - 51s 457ms/step - loss: 0.2945 - dice_coef: 0.6926 - val_loss: 0.1797 - val_dice_coef: 0.6886\n","\n","Epoch 00008: val_loss improved from 0.24354 to 0.17970, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 9/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1837 - dice_coef: 0.6929 - val_loss: 0.2799 - val_dice_coef: 0.7106\n","\n","Epoch 00009: val_loss did not improve from 0.17970\n","Epoch 10/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.2989 - dice_coef: 0.7026 - val_loss: 0.2052 - val_dice_coef: 0.6860\n","\n","Epoch 00010: val_loss did not improve from 0.17970\n","Epoch 11/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1849 - dice_coef: 0.6945 - val_loss: 0.1941 - val_dice_coef: 0.6838\n","\n","Epoch 00011: val_loss did not improve from 0.17970\n","Epoch 12/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.2135 - dice_coef: 0.7014 - val_loss: 0.3071 - val_dice_coef: 0.6731\n","\n","Epoch 00012: val_loss did not improve from 0.17970\n","Epoch 13/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.2360 - dice_coef: 0.6984 - val_loss: 0.1559 - val_dice_coef: 0.6951\n","\n","Epoch 00013: val_loss improved from 0.17970 to 0.15588, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 14/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1550 - dice_coef: 0.7066 - val_loss: 0.2222 - val_dice_coef: 0.6799\n","\n","Epoch 00014: val_loss did not improve from 0.15588\n","Epoch 15/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.2091 - dice_coef: 0.7086 - val_loss: 0.1922 - val_dice_coef: 0.7111\n","\n","Epoch 00015: val_loss did not improve from 0.15588\n","Epoch 16/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.2392 - dice_coef: 0.7139 - val_loss: 0.1396 - val_dice_coef: 0.7305\n","\n","Epoch 00016: val_loss improved from 0.15588 to 0.13965, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 17/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1976 - dice_coef: 0.7282 - val_loss: 0.1465 - val_dice_coef: 0.7078\n","\n","Epoch 00017: val_loss did not improve from 0.13965\n","Epoch 18/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1446 - dice_coef: 0.7210 - val_loss: 0.1677 - val_dice_coef: 0.6878\n","\n","Epoch 00018: val_loss did not improve from 0.13965\n","Epoch 19/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1799 - dice_coef: 0.7240 - val_loss: 0.1313 - val_dice_coef: 0.7194\n","\n","Epoch 00019: val_loss improved from 0.13965 to 0.13135, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 20/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1586 - dice_coef: 0.7334 - val_loss: 0.1356 - val_dice_coef: 0.7573\n","\n","Epoch 00020: val_loss did not improve from 0.13135\n","Epoch 21/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1290 - dice_coef: 0.7535 - val_loss: 0.1671 - val_dice_coef: 0.7077\n","\n","Epoch 00021: val_loss did not improve from 0.13135\n","Epoch 22/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1459 - dice_coef: 0.7284 - val_loss: 0.1432 - val_dice_coef: 0.7226\n","\n","Epoch 00022: val_loss did not improve from 0.13135\n","Epoch 23/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1636 - dice_coef: 0.7498 - val_loss: 0.1218 - val_dice_coef: 0.7790\n","\n","Epoch 00023: val_loss improved from 0.13135 to 0.12176, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 24/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1808 - dice_coef: 0.7387 - val_loss: 0.1537 - val_dice_coef: 0.7478\n","\n","Epoch 00024: val_loss did not improve from 0.12176\n","Epoch 25/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1210 - dice_coef: 0.7659 - val_loss: 0.1234 - val_dice_coef: 0.7288\n","\n","Epoch 00025: val_loss did not improve from 0.12176\n","Epoch 26/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1236 - dice_coef: 0.7651 - val_loss: 0.1363 - val_dice_coef: 0.7488\n","\n","Epoch 00026: val_loss did not improve from 0.12176\n","Epoch 27/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1220 - dice_coef: 0.7635 - val_loss: 0.1357 - val_dice_coef: 0.8069\n","\n","Epoch 00027: val_loss did not improve from 0.12176\n","Epoch 28/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0952 - dice_coef: 0.8135 - val_loss: 0.1293 - val_dice_coef: 0.7135\n","\n","Epoch 00028: val_loss did not improve from 0.12176\n","Epoch 29/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1331 - dice_coef: 0.7892 - val_loss: 0.1339 - val_dice_coef: 0.7406\n","\n","Epoch 00029: val_loss did not improve from 0.12176\n","Epoch 30/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1104 - dice_coef: 0.7912 - val_loss: 0.1747 - val_dice_coef: 0.7169\n","\n","Epoch 00030: val_loss did not improve from 0.12176\n","Epoch 31/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1255 - dice_coef: 0.7859 - val_loss: 0.1172 - val_dice_coef: 0.8086\n","\n","Epoch 00031: val_loss improved from 0.12176 to 0.11719, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 32/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1376 - dice_coef: 0.8055 - val_loss: 0.1046 - val_dice_coef: 0.8188\n","\n","Epoch 00032: val_loss improved from 0.11719 to 0.10462, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 33/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0970 - dice_coef: 0.8186 - val_loss: 0.1178 - val_dice_coef: 0.7769\n","\n","Epoch 00033: val_loss did not improve from 0.10462\n","Epoch 34/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1351 - dice_coef: 0.7666 - val_loss: 0.1123 - val_dice_coef: 0.7942\n","\n","Epoch 00034: val_loss did not improve from 0.10462\n","Epoch 35/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0946 - dice_coef: 0.8185 - val_loss: 0.1230 - val_dice_coef: 0.7590\n","\n","Epoch 00035: val_loss did not improve from 0.10462\n","Epoch 36/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0949 - dice_coef: 0.8027 - val_loss: 0.1079 - val_dice_coef: 0.8155\n","\n","Epoch 00036: val_loss did not improve from 0.10462\n","Epoch 37/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0935 - dice_coef: 0.8305 - val_loss: 0.1453 - val_dice_coef: 0.7634\n","\n","Epoch 00037: val_loss did not improve from 0.10462\n","Epoch 38/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1668 - dice_coef: 0.7688 - val_loss: 0.1180 - val_dice_coef: 0.7779\n","\n","Epoch 00038: val_loss did not improve from 0.10462\n","Epoch 39/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1122 - dice_coef: 0.7920 - val_loss: 0.0993 - val_dice_coef: 0.8343\n","\n","Epoch 00039: val_loss improved from 0.10462 to 0.09928, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 40/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1021 - dice_coef: 0.8280 - val_loss: 0.1041 - val_dice_coef: 0.8201\n","\n","Epoch 00040: val_loss did not improve from 0.09928\n","Epoch 41/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1278 - dice_coef: 0.8156 - val_loss: 0.1100 - val_dice_coef: 0.8490\n","\n","Epoch 00041: val_loss did not improve from 0.09928\n","Epoch 42/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1032 - dice_coef: 0.8138 - val_loss: 0.0901 - val_dice_coef: 0.8399\n","\n","Epoch 00042: val_loss improved from 0.09928 to 0.09011, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 43/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1234 - dice_coef: 0.8351 - val_loss: 0.0907 - val_dice_coef: 0.8276\n","\n","Epoch 00043: val_loss did not improve from 0.09011\n","Epoch 44/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0865 - dice_coef: 0.8338 - val_loss: 0.0875 - val_dice_coef: 0.8662\n","\n","Epoch 00044: val_loss improved from 0.09011 to 0.08749, saving model to /content/drive/My Drive/segmentation/weightsPSP/\n","Epoch 45/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.1125 - dice_coef: 0.8223 - val_loss: 0.1030 - val_dice_coef: 0.8626\n","\n","Epoch 00045: val_loss did not improve from 0.08749\n","Epoch 46/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0872 - dice_coef: 0.8629 - val_loss: 0.0993 - val_dice_coef: 0.8656\n","\n","Epoch 00046: val_loss did not improve from 0.08749\n","Epoch 47/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0572 - dice_coef: 0.8865 - val_loss: 0.1025 - val_dice_coef: 0.8516\n","\n","Epoch 00047: val_loss did not improve from 0.08749\n","Epoch 48/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0756 - dice_coef: 0.8778 - val_loss: 0.0898 - val_dice_coef: 0.8671\n","\n","Epoch 00048: val_loss did not improve from 0.08749\n","Epoch 49/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0552 - dice_coef: 0.8917 - val_loss: 0.1086 - val_dice_coef: 0.8865\n","\n","Epoch 00049: val_loss did not improve from 0.08749\n","Epoch 50/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0561 - dice_coef: 0.8997 - val_loss: 0.0931 - val_dice_coef: 0.9012\n","\n","Epoch 00050: val_loss did not improve from 0.08749\n","Epoch 51/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0529 - dice_coef: 0.9074 - val_loss: 0.1150 - val_dice_coef: 0.8876\n","\n","Epoch 00051: val_loss did not improve from 0.08749\n","Epoch 52/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0527 - dice_coef: 0.9119 - val_loss: 0.0989 - val_dice_coef: 0.9088\n","\n","Epoch 00052: val_loss did not improve from 0.08749\n","Epoch 53/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0477 - dice_coef: 0.9216 - val_loss: 0.1187 - val_dice_coef: 0.9123\n","\n","Epoch 00053: val_loss did not improve from 0.08749\n","Epoch 54/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0486 - dice_coef: 0.9250 - val_loss: 0.0971 - val_dice_coef: 0.9145\n","\n","Epoch 00054: val_loss did not improve from 0.08749\n","Epoch 55/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0524 - dice_coef: 0.9247 - val_loss: 0.1152 - val_dice_coef: 0.9198\n","\n","Epoch 00055: val_loss did not improve from 0.08749\n","Epoch 56/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0437 - dice_coef: 0.9381 - val_loss: 0.1374 - val_dice_coef: 0.9241\n","\n","Epoch 00056: val_loss did not improve from 0.08749\n","Epoch 57/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0685 - dice_coef: 0.9027 - val_loss: 0.1009 - val_dice_coef: 0.8806\n","\n","Epoch 00057: val_loss did not improve from 0.08749\n","Epoch 58/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0638 - dice_coef: 0.8875 - val_loss: 0.1115 - val_dice_coef: 0.8353\n","\n","Epoch 00058: val_loss did not improve from 0.08749\n","Epoch 59/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0577 - dice_coef: 0.8862 - val_loss: 0.1131 - val_dice_coef: 0.9223\n","\n","Epoch 00059: val_loss did not improve from 0.08749\n","Epoch 60/60\n","112/112 [==============================] - 51s 454ms/step - loss: 0.0398 - dice_coef: 0.9312 - val_loss: 0.1010 - val_dice_coef: 0.8601\n","\n","Epoch 00060: val_loss did not improve from 0.08749\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F7G3SFaYLJHF"},"source":["psp_net.save_weights('/content/drive/My Drive/segmentation/weightsPSP/model_resnet.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLioqSQMLLdQ"},"source":["psp_net = PSPNet()\r\n","psp_net.load_weights('/content/drive/My Drive/segmentation/weightsPSP/model_resnet.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwcZ0Vr0LF0Q"},"source":["predictions = psp_net.predict(xVal, batch_size = 2)\r\n","\r\n","for i, pred_image in enumerate(predictions):\r\n","  actual_image = xVal[i]\r\n","  pred = index2color(pred_image, actual_image).astype(np.uint8)\r\n","  pred = Image.fromarray(pred)\r\n","  pred.save(directory + f\"predicted/PSP/дог{i}.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vm6K9t4Hzd2k"},"source":["Генератор оказался не успешным (код работает, но размер картинки слишком большой)"]},{"cell_type":"code","metadata":{"id":"EFliFLAwoSkg"},"source":["# class MyGenerator(tf.keras.utils.Sequence):\r\n","#   def __init__(self, X_filepath, y_filepath, batch_size=4, num_classes=2, shuffle=True):\r\n","#      assert len(os.listdir(X_filepath)) == len(os.listdir(y_filepath))\r\n","#      self.batch_size = batch_size\r\n","#      self.X_filepath = X_filepath\r\n","#      self.y_filepath = y_filepath\r\n","#      self.indices = [i for i in range(len(os.listdir(self.X_filepath)))]\r\n","#      self.num_classes = num_classes\r\n","#      self.shuffle = shuffle\r\n","#      self.on_epoch_end()\r\n","#      self.SEED = 100\r\n","\r\n","#   def on_epoch_end(self):\r\n","#      self.index = np.arange(len(self.indices))\r\n","#      if self.shuffle == True:\r\n","#           np.random.shuffle(self.index)\r\n","\r\n","#   def __len__(self):\r\n","#      # Denotes the number of batches per epoch\r\n","#      return len(self.indices) // self.batch_size\r\n","\r\n","#   def __getitem__(self, index):\r\n","#      # Generate one batch of data\r\n","#      # Generate indices of the batch\r\n","#      index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\r\n","#      # Find list of IDs\r\n","#      batch = [self.indices[k] for k in index]\r\n","#      # Generate data\r\n","#      X, y = self.get_data(batch)\r\n","#      y = utils.to_categorical(y, 2)\r\n","#      return X, y\r\n","\r\n","#   def get_item(self, index):\r\n","#      # Generate one batch of data\r\n","#      # Generate indices of the batch\r\n","#      index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\r\n","#      # Find list of IDs\r\n","#      batch = [self.indices[k] for k in index]\r\n","#      # Generate data\r\n","#      X, y = self.get_data(batch)\r\n","#      y = utils.to_categorical(y, num_classes)\r\n","#      return X, y\r\n","\r\n","#   def get_data(self, batch):\r\n","#     X_data = []\r\n","#     y_data = []\r\n","#     for index in batch:\r\n","#       X = np.asarray(Image.open(self.X_filepath + os.listdir(self.X_filepath)[index]))\r\n","#       y = np.asarray(Image.open(self.y_filepath + os.listdir(self.y_filepath)[index]).convert('1'))\r\n","#       X_data.append(X)\r\n","#       y_data.append(y)\r\n","\r\n","#     X_data = np.array(X_data)\r\n","#     y_data = np.array(y_data)\r\n","#     return X_data, y_data\r\n","\r\n","# train_generator = MyGenerator(directory + 'xTrain_generator/', directory + 'yTrain_generator/') \r\n","# test_generator = MyGenerator(directory + 'xTrain_generator/', directory + 'yTrain_generator/')  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EUIslvt3JrI"},"source":["# '''\r\n","#   Функция создания сети\r\n","#     Входные параметры:\r\n","#     - num_classes - количество классов\r\n","#     - input_shape - размерность карты сегментации\r\n","# '''\r\n","# def unetWithMask(num_classes = num_classes, input_shape = (img_width, img_height, 3)):\r\n","#     img_input = Input(input_shape)                                      # Создаем входной слой с размерностью input_shape\r\n","\r\n","#     # Block 1\r\n","#     x = Conv2D(16, (9, 9), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(16, (9, 9), padding='same', name='block1_conv2')(x)      # Добавляем Conv2D-слой с 64-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_1_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_1_out\r\n","    \r\n","#     block_1_out_mask = Conv2D(16, (1, 1), padding='same', activation = 'elu')(block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\r\n","\r\n","#     x = Conv2D(32, (8, 8), strides = (2, 2), padding = 'same', activation = 'elu')(block_1_out) # Добавляем слой MaxPooling2D\r\n","\r\n","#     # Block 2\r\n","#     x = Conv2D(32, (8, 8), padding='same', name='block2_conv1')(x)     # Добавляем Conv2D-слой с 128-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x) # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(32, (8, 8), padding='same', name='block2_conv2')(x)     # Добавляем Conv2D-слой с 128-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_2_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_2_out\r\n","\r\n","#     block_2_out_mask = Conv2D(32, (1, 1), padding='same', activation = 'elu')(block_2_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_2_out_mask\r\n","    \r\n","#     x = Conv2D(64, (7, 7), strides = (2, 2), padding = 'same', activation = 'elu')(block_2_out)                                     # Добавляем слой MaxPooling2D\r\n","\r\n","#     # Block 3\r\n","#     x = Conv2D(64, (7, 7), padding='same', name='block3_conv1')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(64, (7, 7), padding='same', name='block3_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(64, (7, 7), padding='same', name='block3_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_3_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_3_out\r\n","\r\n","#     block_3_out_mask = Conv2D(64, (1, 1), padding='same', activation = 'elu')(block_3_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_3_out_mask\r\n","        \r\n","#     x = Conv2D(96, (6, 6), strides = (2, 2), padding = 'same', activation = 'elu')(block_3_out)                                     # Добавляем слой MaxPooling2D\r\n","\r\n","#      # Block 4\r\n","#     x = Conv2D(96, (6, 6), padding='same', name='block4_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(96, (6, 6), padding='same', name='block4_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(96, (6, 6), padding='same', name='block4_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_4_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_4_out\r\n","\r\n","#     block_4_out_mask = Conv2D(96, (1, 1), padding='same', activation = 'elu')(block_4_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_4_out_mask\r\n","            \r\n","#     x = Conv2D(128, (5, 5), strides = (2, 2), padding = 'same', activation = 'elu')(block_4_out)                                     # Добавляем слой MaxPooling2D\r\n","\r\n","#     # Block 5\r\n","#     x = Conv2D(128, (5, 5), padding='same', name='block5_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(128, (5, 5), padding='same', name='block5_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(128, (5, 5), padding='same', name='block5_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_5_out = Activation('elu')(x)                                 # Добавляем слой Activation\r\n","\r\n","#     block_5_out_mask = Conv2D(128, (1, 1), padding='same', activation = 'elu')(block_5_out)\r\n","\r\n","#     x = Conv2D(148, (4, 4), strides = (2, 2), padding = 'same', activation = 'elu')(block_5_out)\r\n","\r\n","#     #Block 6\r\n","#     x = Conv2D(148, (4, 4), padding='same', name='block6_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(148, (4, 4), padding='same', name='block6_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(148, (4, 4), padding='same', name='block6_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_6_out = Activation('elu')(x)                                 # Добавляем слой Activation\r\n","\r\n","#     block_6_out_mask = Conv2D(148, (1, 1), padding='same', activation = 'elu')(block_6_out)\r\n","\r\n","#     x = Conv2D(192, (4, 4), strides = (2, 2), padding = 'same', activation = 'elu')(block_6_out)\r\n","\r\n","#     #Block 7\r\n","#     x = Conv2D(192, (3, 3), padding='same', name='block7_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(192, (3, 3), padding='same', name='block7_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(192, (3, 3), padding='same', name='block7_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_7_out = Activation('elu')(x)                                 # Добавляем слой Activation\r\n","\r\n","#     block_7_out_mask = Conv2D(192, (1, 1), padding='same', activation = 'elu')(block_7_out)\r\n","\r\n","#     x = Conv2D(256, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_7_out)\r\n","\r\n","#     #Block 8\r\n","#     x = Conv2D(256, (3, 3), padding='same', name='block8_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(256, (3, 3), padding='same', name='block8_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(256, (3, 3), padding='same', name='block8_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)\r\n","#     x = Conv2D(256, (1, 1), padding='same')(x)\r\n","\r\n","\r\n","#     # UP 1\r\n","#     x = Conv2DTranspose(192, (3, 3), strides=(2, 2), padding='same')(x)\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_7_out, block_7_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(192, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(192, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)    \r\n","    \r\n","\r\n","#     # UP 2\r\n","#     x = Conv2DTranspose(148, (4, 4), strides=(2, 2), padding='same')(x)\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_6_out, block_6_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(148, (4, 4), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(148, (4, 4), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)    \r\n","\r\n","#     # UP 3\r\n","#     x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_5_out, block_5_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(128, (5, 5), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(128, (5, 5), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)    \r\n","    \r\n"," \r\n","#     # UP 4\r\n","#     x = Conv2DTranspose(96, (6, 6), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_4_out, block_4_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(96, (6, 6), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(96, (6, 6), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     # UP 5\r\n","#     x = Conv2DTranspose(64, (7, 7), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 256 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_3_out, block_3_out_mask])                 # Объединем текущий слой со слоем block_3_out и слоем-маской block_3_out_mask\r\n","#     x = Conv2D(64, (7, 7), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(64, (7, 7), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     # UP 6\r\n","#     x = Conv2DTranspose(32, (8, 8), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_2_out, block_2_out_mask])                 # Объединем текущий слой со слоем block_2_out и слоем-маской block_2_out_mask\r\n","#     x = Conv2D(32, (8, 8), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(32, (8, 8), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     # UP 7\r\n","#     x = Conv2DTranspose(16, (9, 9), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\r\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_1_out, block_1_out_mask])                # Объединем текущий слой со слоем block_1_out и слоем-маской block_1_out_mask\r\n","#     x = Conv2D(16, (9, 9), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(16, (9, 9), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     inputmask = Conv2D(16, (9, 9), activation = 'elu', padding='same')(img_input)\r\n","#     x = Concatenate()([x, inputmask])\r\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(num_classes, (9, 9), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\r\n","\r\n","#     model = Model(img_input, x)                                        # Создаем модель с входом 'img_input' и выходом 'x'\r\n","\r\n","#     # Компилируем модель \r\n","#     model.compile(optimizer=Adam(lr = 0.0001),\r\n","#                   loss='categorical_crossentropy',\r\n","#                   metrics=[dice_coef])\r\n","    \r\n","#     return model                                                       # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3GHWp9Ic-Eu"},"source":["# '''\r\n","#   Функция создания сети\r\n","#     Входные параметры:\r\n","#     - num_classes - количество классов\r\n","#     - input_shape - размерность карты сегментации\r\n","# '''\r\n","# def unetWithMask(num_classes = num_classes, input_shape = (img_width, img_height, 3)):\r\n","#     img_input = Input(input_shape)                                      # Создаем входной слой с размерностью input_shape\r\n","\r\n","#     # Block 1\r\n","#     x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)      # Добавляем Conv2D-слой с 64-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_1_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_1_out\r\n","    \r\n","#     block_1_out_mask = Conv2D(128, (1, 1), padding='same', activation = 'elu')(block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\r\n","\r\n","#     x = Conv2D(64, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_1_out) # Добавляем слой MaxPooling2D\r\n","\r\n","#     # Block 2\r\n","#     x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)     # Добавляем Conv2D-слой с 128-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x) # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)     # Добавляем Conv2D-слой с 128-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_2_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_2_out\r\n","\r\n","#     block_2_out_mask = Conv2D(128, (1, 1), padding='same', activation = 'elu')(block_2_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_2_out_mask\r\n","    \r\n","#     x = Conv2D(192, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_2_out)                                     # Добавляем слой MaxPooling2D\r\n","\r\n","#     # Block 3\r\n","#     x = Conv2D(192, (3, 3), padding='same', name='block3_conv1')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(192, (3, 3), padding='same', name='block3_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(192, (3, 3), padding='same', name='block3_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_3_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_3_out\r\n","\r\n","#     block_3_out_mask = Conv2D(192, (1, 1), padding='same', activation = 'elu')(block_3_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_3_out_mask\r\n","        \r\n","#     x = Conv2D(256, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_3_out)                                     # Добавляем слой MaxPooling2D\r\n","\r\n","#      # Block 4\r\n","#     x = Conv2D(256, (3, 3), padding='same', name='block4_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(256, (3, 3), padding='same', name='block4_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(256, (3, 3), padding='same', name='block4_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_4_out = Activation('elu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_4_out\r\n","\r\n","#     block_4_out_mask = Conv2D(256, (1, 1), padding='same', activation = 'elu')(block_4_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_4_out_mask\r\n","            \r\n","#     x = Conv2D(384, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_4_out)                                     # Добавляем слой MaxPooling2D\r\n","\r\n","#     # Block 5\r\n","#     x = Conv2D(384, (3, 3), padding='same', name='block5_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(384, (3, 3), padding='same', name='block5_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(384, (3, 3), padding='same', name='block5_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_5_out = Activation('elu')(x)                                 # Добавляем слой Activation\r\n","\r\n","#     block_5_out_mask = Conv2D(384, (1, 1), padding='same', activation = 'elu')(block_5_out)\r\n","\r\n","#     x = Conv2D(512, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_5_out)\r\n","\r\n","#     #Block 6\r\n","#     x = Conv2D(512, (3, 3), padding='same', name='block6_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(512, (3, 3), padding='same', name='block6_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(512, (3, 3), padding='same', name='block6_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_6_out = Activation('elu')(x)                                 # Добавляем слой Activation\r\n","\r\n","#     block_6_out_mask = Conv2D(512, (1, 1), padding='same', activation = 'elu')(block_6_out)\r\n","\r\n","#     x = Conv2D(768, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_6_out)\r\n","\r\n","#     #Block 7\r\n","#     x = Conv2D(768, (3, 3), padding='same', name='block7_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(768, (3, 3), padding='same', name='block7_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(768, (3, 3), padding='same', name='block7_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     block_7_out = Activation('elu')(x)                                 # Добавляем слой Activation\r\n","\r\n","#     block_7_out_mask = Conv2D(768, (1, 1), padding='same', activation = 'elu')(block_7_out)\r\n","\r\n","#     x = Conv2D(1024, (3, 3), strides = (2, 2), padding = 'same', activation = 'elu')(block_7_out)\r\n","\r\n","#     #Block 8\r\n","#     x = Conv2D(1024, (3, 3), padding='same', name='block8_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(1024, (3, 3), padding='same', name='block8_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(1024, (3, 3), padding='same', name='block8_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)\r\n","#     x = Conv2D(1024, (1, 1), padding='same')(x)\r\n","\r\n","\r\n","#     # UP 1\r\n","#     x = Conv2DTranspose(768, (2, 2), strides=(2, 2), padding='same')(x)\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_7_out, block_7_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(768, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(768, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)    \r\n","    \r\n","\r\n","#     # UP 2\r\n","#     x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_6_out, block_6_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(512, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(512, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)    \r\n","\r\n","#     # UP 3\r\n","#     x = Conv2DTranspose(384, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_5_out, block_5_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(384, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(384, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)    \r\n","    \r\n"," \r\n","#     # UP 4\r\n","#     x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_4_out, block_4_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\r\n","#     x = Conv2D(256, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(256, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     # UP 5\r\n","#     x = Conv2DTranspose(192, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 256 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_3_out, block_3_out_mask])                 # Объединем текущий слой со слоем block_3_out и слоем-маской block_3_out_mask\r\n","#     x = Conv2D(192, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(192, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     # UP 6\r\n","#     x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_2_out, block_2_out_mask])                 # Объединем текущий слой со слоем block_2_out и слоем-маской block_2_out_mask\r\n","#     x = Conv2D(128, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(128, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                           # Добавляем слой Activation\r\n","\r\n","#     # UP 7\r\n","#     x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\r\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\r\n","\r\n","#     x = concatenate([x, block_1_out, block_1_out_mask])                # Объединем текущий слой со слоем block_1_out и слоем-маской block_1_out_mask\r\n","#     x = Conv2D(64, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(64, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\r\n","#     inputmask = Conv2D(64, (3, 3), activation = 'elu', padding='same')(img_input)\r\n","#     x = Concatenate()([x, inputmask])\r\n","#     x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\r\n","#     x = Activation('elu')(x)                                          # Добавляем слой Activation\r\n","\r\n","#     x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\r\n","\r\n","#     model = Model(img_input, x)                                        # Создаем модель с входом 'img_input' и выходом 'x'\r\n","\r\n","#     # Компилируем модель \r\n","#     model.compile(optimizer=Adam(lr = 0.0001),\r\n","#                   loss='categorical_crossentropy',\r\n","#                   metrics=[dice_coef])\r\n","    \r\n","#     return model                                                       # Возвращаем сформированную модель"],"execution_count":null,"outputs":[]}]}