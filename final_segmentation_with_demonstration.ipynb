{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6042,"status":"ok","timestamp":1618337531573,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"mQ8iN9gArPDd"},"outputs":[],"source":["from tensorflow.keras.models import Model # Импортируем модели keras: Model\n","from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, Add, MaxPooling2D, Conv2D, BatchNormalization # Импортируем стандартные слои keras\n","from tensorflow.keras import backend as K # Импортируем модуль backend keras'а\n","from tensorflow.keras.optimizers import Adam # Импортируем оптимизатор Adam\n","from tensorflow.keras import utils # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n","import tensorflow as tf\n","from google.colab import files # Импортируем Модуль files для работы с файлами\n","import matplotlib.pyplot as plt # Импортируем модуль pyplot библиотеки matplotlib для построения графиков\n","from tensorflow.keras.preprocessing import image # Импортируем модуль image для работы с изображениями\n","import numpy as np # Импортируем библиотеку numpy\n","from sklearn.model_selection import train_test_split\n","import time\n","import random\n","import shutil\n","import os # Импортируем библиотеку os для раоты с фаловой системой\n","from PIL import Image # импортируем модель Image для работы с изображениями\n","import seaborn as sns\n","from tensorflow.keras.models import load_model, save_model\n","import pickle\n","\n","import numba as nb\n","import cv2 as cv\n","from PIL import Image\n","from numpy.lib.stride_tricks import as_strided\n","sns.set_style('darkgrid')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6021,"status":"ok","timestamp":1618337531575,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"H0d19QiyrUEW","outputId":"ac7ba756-3e5b-4ac0-c99c-f4cad3686360"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive # Подключаем гугл-диск\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6018,"status":"ok","timestamp":1618337531576,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"TLbFxmtSrWOS"},"outputs":[],"source":["# Глобальные параметры\n","num_classes = 2 # Задаем количество классов на изображении\n","directory = '/content/drive/My Drive/segmentation/' # Указываем путь к обучающей выборке с оригинальными изображения"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6016,"status":"ok","timestamp":1618337531578,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"IXiW0OtKrX5q"},"outputs":[],"source":["def order_points(pts):\n","\t# initialzie a list of coordinates that will be ordered\n","\t# such that the first entry in the list is the top-left,\n","\t# the second entry is the top-right, the third is the\n","\t# bottom-right, and the fourth is the bottom-left\n","\trect = np.zeros((4, 2), dtype = \"float32\")\n","\t# the top-left point will have the smallest sum, whereas\n","\t# the bottom-right point will have the largest sum\n","\ts = pts.sum(axis = 1)\n","\trect[0] = pts[np.argmin(s)]\n","\trect[2] = pts[np.argmax(s)]\n","\t# now, compute the difference between the points, the\n","\t# top-right point will have the smallest difference,\n","\t# whereas the bottom-left will have the largest difference\n","\tdiff = np.diff(pts, axis = 1)\n","\trect[1] = pts[np.argmin(diff)]\n","\trect[3] = pts[np.argmax(diff)]\n","\t# return the ordered coordinates\n","\treturn rect\n","\n","def four_point_transform(image, pts):\n","\t# obtain a consistent order of the points and unpack them\n","\t# individually\n","\trect = order_points(pts)\n","\t(tl, tr, br, bl) = rect\n","\t# compute the width of the new image, which will be the\n","\t# maximum distance between bottom-right and bottom-left\n","\t# x-coordiates or the top-right and top-left x-coordinates\n","\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n","\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n","\tmaxWidth = max(int(widthA), int(widthB))\n","\t# compute the height of the new image, which will be the\n","\t# maximum distance between the top-right and bottom-right\n","\t# y-coordinates or the top-left and bottom-left y-coordinates\n","\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n","\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n","\tmaxHeight = max(int(heightA), int(heightB))\n","\t# now that we have the dimensions of the new image, construct\n","\t# the set of destination points to obtain a \"birds eye view\",\n","\t# (i.e. top-down view) of the image, again specifying points\n","\t# in the top-left, top-right, bottom-right, and bottom-left\n","\t# order\n","\tdst = np.array([\n","\t\t[0, 0],\n","\t\t[maxWidth - 1, 0],\n","\t\t[maxWidth - 1, maxHeight - 1],\n","\t\t[0, maxHeight - 1]], dtype = \"float32\")\n","\t# compute the perspective transform matrix and then apply it\n","\tM = cv.getPerspectiveTransform(rect, dst)\n","\twarped = cv.warpPerspective(image, M, (maxWidth, maxHeight))\n","\t# return the warped image\n","\treturn warped\n","\n","def get_coordinates_logic(img, factor = 100):\n","  color = (384, 256, 384)\n","  width = img.shape[1]\n","  height = img.shape[0]\n","  x_scale = width - factor + 1\n","  y_scale = height - factor + 1\n","\n","  try:\n","    temp_img = img[0:factor, 0:factor, :]\n","    w1 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) #min - minimum value along axis/max - maximum value along axis\n","    h1 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) #[0] - target vertical axis (height)/ [1] - target horizontal axis (width)\n","    temp_img = img[0:factor, -factor:, :]\n","    w2 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) + x_scale\n","    h2 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[0])\n","    temp_img = img[-factor:, -factor:, :]\n","    w3 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) + x_scale\n","    h3 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) + y_scale\n","    temp_img = img[-factor:, 0:factor, :]\n","    w4 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[1])\n","    h4 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) + y_scale\n","  except:\n","    w1, w2, w3, w4, h1, h2, h3, h4 = get_coordinates_logic(img, factor = factor + 50)\n","  \n","  return w1, w2, w3, w4, h1, h2, h3, h4\n","\n","def process_img(img):\n","\n","  img = img.copy()\n","  height = img.shape[0]\n","  width = img.shape[1]\n","\n","  itemindex = np.array(np.where(np.all(img == (384, 256, 384), axis=-1))) #Set pixel values to something outside of the uint8 range\n","                                                                          #(to avoid interfering with any pixels that might be in the image)\n","  minH = min(itemindex[0])  #Height to crop (top)\n","  maxH = max(itemindex[0])  #Height to crop (bottom)\n","  minW = min(itemindex[1])  #Width to crop (left)\n","  maxW = max(itemindex[1])  #Width to crop (right)\n","\n","  pts = np.int32([[minW,minH], [maxW,minH], [minW,maxH], [maxW,maxH]])\n","  img_cropped = img[minH:maxH, minW:maxW]\n","  w1, w2, w3, w4, h1, h2, h3, h4 = get_coordinates_logic(img_cropped)\n","\n","  img_cropped[np.all(img_cropped == (384, 256, 384), axis = -1)] = (255, 255, 255)\n","  img_cropped = img_cropped.astype(np.uint8) #Change back to uint8 datatype\n","  result = four_point_transform(img_cropped, np.array([[w1, h1], [w2, h2], [w3, h3], [w4, h4]])) #Four-point transform (trapezoid to rectangle)\n","  return result\n","\n","def index2color(segment_img, actual_img, color = (128, 0, 128), final_mode = False):\n","  new_img = np.zeros_like(actual_img).astype(np.uint16)\n","  \n","  segment_img = cv.resize(segment_img, (actual_img.shape[1], actual_img.shape[0]), interpolation = cv.INTER_LANCZOS4)\n","  segment_img = np.round(segment_img)\n","\n","  zero_index = np.where(np.all(segment_img == (1, 0), axis=-1))\n","  ones_index = np.where(np.all(segment_img == (0, 1), axis=-1))\n","  \n","  new_img[zero_index] = (384, 256, 384)\n","  new_img[ones_index] = actual_img[ones_index]\n","  \n","  if final_mode:\n","    new_img = process_img(new_img)\n","  return new_img"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6015,"status":"ok","timestamp":1618337531580,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"xRHh85z5yMAH"},"outputs":[],"source":["img_width = 512\n","img_height = 768"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6013,"status":"ok","timestamp":1618337531581,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"WioagQp1vYt2"},"outputs":[],"source":["def get_model_from_file():\n","  def dice_coef(y_true, y_pred):\n","    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.) # Возвращаем площадь пересечения деленную на площадь объединения двух областей\n","\n","\n","  model = load_model(directory + 'weightsUS/acc09811.h5')\n","  model.compile(optimizer=Adam(lr = 0.0001),\n","                loss='categorical_crossentropy',\n","                metrics=[dice_coef])\n","    \n","  return model"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6011,"status":"ok","timestamp":1618337531582,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"gvOt7g48vrv2"},"outputs":[],"source":["def predict_image(img_path, model):\n","  img = np.array(Image.open(img_path)) #Открываем картинку с входного пути\n","  \n","  actual_height = img.shape[0]         #Записываем высоту оригинальной картинки\n","  actual_width = img.shape[1]          #Записываем шырину оригинальной картинки\n","\n","  width = 512                          #Ширина которая будет подаваться в НС\n","  height = 768                         #Высота которая будет подаваться в НС\n","  input_img = cv.resize(img, (width, height), interpolation = cv.INTER_LANCZOS4) #Делаем Reshape для входа в НС\n","  actual_img = cv.resize(img, (width * 2, height * 2), interpolation = cv.INTER_LANCZOS4) #Делаем Reshape для настоящей картинки\n","  input_img = np.expand_dims(input_img, axis = 0) #Добавляем ось для НС\n","  pred_image = model.predict(input_img/255).reshape((height, width, num_classes)) #Получаем результат с НС и делаем обратный предикт\n","  \n","  pred = index2color(pred_image, actual_img, color = (255, 255, 255), final_mode = True).astype(np.uint8) #Обрабатываем данные с сегментации\n","  pred = cv.resize(pred, (actual_width, actual_height), interpolation = cv.INTER_LANCZOS4) #Делаем reshape обратно\n","\n","  pred = Image.fromarray(pred) #Переводим с numpy массива в картинку\n","  return pred #Возвращаем картинку"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1-5wB4-MWaSqgLEYxh_3B-97WztxVpgnG"},"executionInfo":{"elapsed":72144,"status":"ok","timestamp":1618337597732,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"},"user_tz":-180},"id":"CiVAjjLHvgge","outputId":"cf827cdb-1232-4c3d-91df-2e736cb31e2d"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["model_best = get_model_from_file()\n","predict_image(directory + 'orig/дог200.jpg', model = model_best)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1GYhXDMS3vX3WCjmiktoxOKEnxULWmpVE"},"id":"ggupiqchvnkU","outputId":"20161a6e-0304-4218-978d-d0698c9d9910"},"outputs":[],"source":["for i, filename in enumerate(os.listdir(directory + 'orig/')):\n","  pred = predict_image(directory + f'orig/{filename}', model = model_best)\n","  plt.figure(figsize = (20, 20))\n","  print(str(i) + '_' * 50)\n","  plt.imshow(np.array(pred))\n","  plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPvHkAKBc2UGmiwRz9RS4xs","collapsed_sections":[],"name":"final_segmentation_with_demonstration.ipynb","provenance":[{"file_id":"1q-q19_2tYTxPBgK5isWwH7oLlG8rvlyg","timestamp":1612556014601}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}