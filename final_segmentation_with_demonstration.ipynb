{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_segmentation_with_demonstration.ipynb","provenance":[{"file_id":"1q-q19_2tYTxPBgK5isWwH7oLlG8rvlyg","timestamp":1612556014601}],"collapsed_sections":[],"authorship_tag":"ABX9TyMWr93GUBi6+wAWp9xYyxP+"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"mQ8iN9gArPDd","executionInfo":{"status":"ok","timestamp":1613587485547,"user_tz":-180,"elapsed":13189,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}}},"source":["from tensorflow.keras.models import Model # Импортируем модели keras: Model\r\n","from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, Add, MaxPooling2D, Conv2D, BatchNormalization # Импортируем стандартные слои keras\r\n","from tensorflow.keras import backend as K # Импортируем модуль backend keras'а\r\n","from tensorflow.keras.optimizers import Adam # Импортируем оптимизатор Adam\r\n","from tensorflow.keras import utils # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\r\n","import tensorflow as tf\r\n","from google.colab import files # Импортируем Модуль files для работы с файлами\r\n","import matplotlib.pyplot as plt # Импортируем модуль pyplot библиотеки matplotlib для построения графиков\r\n","from tensorflow.keras.preprocessing import image # Импортируем модуль image для работы с изображениями\r\n","import numpy as np # Импортируем библиотеку numpy\r\n","from sklearn.model_selection import train_test_split\r\n","import time\r\n","import random\r\n","import shutil\r\n","import os # Импортируем библиотеку os для раоты с фаловой системой\r\n","from PIL import Image # импортируем модель Image для работы с изображениями\r\n","import seaborn as sns\r\n","from tensorflow.keras.models import load_model, save_model\r\n","import pickle\r\n","\r\n","import numba as nb\r\n","import cv2 as cv\r\n","from PIL import Image\r\n","from numpy.lib.stride_tricks import as_strided\r\n","sns.set_style('darkgrid')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0d19QiyrUEW","executionInfo":{"status":"ok","timestamp":1613587480671,"user_tz":-180,"elapsed":24399,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}},"outputId":"bf8f6e38-285b-4690-a0a5-5562d62f9bf7"},"source":["from google.colab import drive # Подключаем гугл-диск\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TLbFxmtSrWOS","executionInfo":{"status":"ok","timestamp":1613587485552,"user_tz":-180,"elapsed":11663,"user":{"displayName":"University of Artificial Intelligence","photoUrl":"","userId":"07499422860102443925"}}},"source":["# Глобальные параметры\r\n","num_classes = 2 # Задаем количество классов на изображении\r\n","directory = '/content/drive/My Drive/segmentation/' # Указываем путь к обучающей выборке с оригинальными изображения"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXiW0OtKrX5q"},"source":["def order_points(pts):\r\n","\t# initialzie a list of coordinates that will be ordered\r\n","\t# such that the first entry in the list is the top-left,\r\n","\t# the second entry is the top-right, the third is the\r\n","\t# bottom-right, and the fourth is the bottom-left\r\n","\trect = np.zeros((4, 2), dtype = \"float32\")\r\n","\t# the top-left point will have the smallest sum, whereas\r\n","\t# the bottom-right point will have the largest sum\r\n","\ts = pts.sum(axis = 1)\r\n","\trect[0] = pts[np.argmin(s)]\r\n","\trect[2] = pts[np.argmax(s)]\r\n","\t# now, compute the difference between the points, the\r\n","\t# top-right point will have the smallest difference,\r\n","\t# whereas the bottom-left will have the largest difference\r\n","\tdiff = np.diff(pts, axis = 1)\r\n","\trect[1] = pts[np.argmin(diff)]\r\n","\trect[3] = pts[np.argmax(diff)]\r\n","\t# return the ordered coordinates\r\n","\treturn rect\r\n","\r\n","def four_point_transform(image, pts):\r\n","\t# obtain a consistent order of the points and unpack them\r\n","\t# individually\r\n","\trect = order_points(pts)\r\n","\t(tl, tr, br, bl) = rect\r\n","\t# compute the width of the new image, which will be the\r\n","\t# maximum distance between bottom-right and bottom-left\r\n","\t# x-coordiates or the top-right and top-left x-coordinates\r\n","\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\r\n","\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\r\n","\tmaxWidth = max(int(widthA), int(widthB))\r\n","\t# compute the height of the new image, which will be the\r\n","\t# maximum distance between the top-right and bottom-right\r\n","\t# y-coordinates or the top-left and bottom-left y-coordinates\r\n","\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\r\n","\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\r\n","\tmaxHeight = max(int(heightA), int(heightB))\r\n","\t# now that we have the dimensions of the new image, construct\r\n","\t# the set of destination points to obtain a \"birds eye view\",\r\n","\t# (i.e. top-down view) of the image, again specifying points\r\n","\t# in the top-left, top-right, bottom-right, and bottom-left\r\n","\t# order\r\n","\tdst = np.array([\r\n","\t\t[0, 0],\r\n","\t\t[maxWidth - 1, 0],\r\n","\t\t[maxWidth - 1, maxHeight - 1],\r\n","\t\t[0, maxHeight - 1]], dtype = \"float32\")\r\n","\t# compute the perspective transform matrix and then apply it\r\n","\tM = cv.getPerspectiveTransform(rect, dst)\r\n","\twarped = cv.warpPerspective(image, M, (maxWidth, maxHeight))\r\n","\t# return the warped image\r\n","\treturn warped\r\n","\r\n","def get_coordinates_logic(img, factor = 100):\r\n","  color = (384, 256, 384)\r\n","  width = img.shape[1]\r\n","  height = img.shape[0]\r\n","  x_scale = width - factor + 1\r\n","  y_scale = height - factor + 1\r\n","\r\n","  try:\r\n","    temp_img = img[0:factor, 0:factor, :]\r\n","    w1 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) #min - minimum value along axis/max - maximum value along axis\r\n","    h1 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) #[0] - target vertical axis (height)/ [1] - target horizontal axis (width)\r\n","    temp_img = img[0:factor, -factor:, :]\r\n","    w2 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) + x_scale\r\n","    h2 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[0])\r\n","    temp_img = img[-factor:, -factor:, :]\r\n","    w3 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[1]) + x_scale\r\n","    h3 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) + y_scale\r\n","    temp_img = img[-factor:, 0:factor, :]\r\n","    w4 = min(np.array(np.where(np.all(temp_img != color, axis=-1)))[1])\r\n","    h4 = max(np.array(np.where(np.all(temp_img != color, axis=-1)))[0]) + y_scale\r\n","  except:\r\n","    w1, w2, w3, w4, h1, h2, h3, h4 = get_coordinates_logic(img, factor = factor + 50)\r\n","  \r\n","  return w1, w2, w3, w4, h1, h2, h3, h4\r\n","\r\n","def process_img(img):\r\n","\r\n","  img = img.copy()\r\n","  height = img.shape[0]\r\n","  width = img.shape[1]\r\n","\r\n","  itemindex = np.array(np.where(np.all(img == (384, 256, 384), axis=-1))) #Set pixel values to something outside of the uint8 range\r\n","                                                                          #(to avoid interfering with any pixels that might be in the image)\r\n","  minH = min(itemindex[0])  #Height to crop (top)\r\n","  maxH = max(itemindex[0])  #Height to crop (bottom)\r\n","  minW = min(itemindex[1])  #Width to crop (left)\r\n","  maxW = max(itemindex[1])  #Width to crop (right)\r\n","\r\n","  pts = np.int32([[minW,minH], [maxW,minH], [minW,maxH], [maxW,maxH]])\r\n","  img_cropped = img[minH:maxH, minW:maxW]\r\n","  w1, w2, w3, w4, h1, h2, h3, h4 = get_coordinates_logic(img_cropped)\r\n","\r\n","  img_cropped[np.all(img_cropped == (384, 256, 384), axis = -1)] = (255, 255, 255)\r\n","  img_cropped = img_cropped.astype(np.uint8) #Change back to uint8 datatype\r\n","  result = four_point_transform(img_cropped, np.array([[w1, h1], [w2, h2], [w3, h3], [w4, h4]])) #Four-point transform (trapezoid to rectangle)\r\n","  return result\r\n","\r\n","def index2color(segment_img, actual_img, color = (128, 0, 128), final_mode = False):\r\n","  new_img = np.zeros_like(actual_img).astype(np.uint16)\r\n","  \r\n","  segment_img = cv.resize(segment_img, (actual_img.shape[1], actual_img.shape[0]), interpolation = cv.INTER_LANCZOS4)\r\n","  segment_img = np.round(segment_img)\r\n","\r\n","  zero_index = np.where(np.all(segment_img == (1, 0), axis=-1))\r\n","  ones_index = np.where(np.all(segment_img == (0, 1), axis=-1))\r\n","  \r\n","  new_img[zero_index] = (384, 256, 384)\r\n","  new_img[ones_index] = actual_img[ones_index]\r\n","  \r\n","  if final_mode:\r\n","    new_img = process_img(new_img)\r\n","  return new_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xRHh85z5yMAH"},"source":["img_width = 512\r\n","img_height = 768"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WioagQp1vYt2"},"source":["def get_model_from_file():\r\n","  def dice_coef(y_true, y_pred):\r\n","    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.) # Возвращаем площадь пересечения деленную на площадь объединения двух областей\r\n","\r\n","\r\n","  model = load_model(directory + 'weightsUS/acc09811.h5')\r\n","  model.compile(optimizer=Adam(lr = 0.0001),\r\n","                loss='categorical_crossentropy',\r\n","                metrics=[dice_coef])\r\n","    \r\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvOt7g48vrv2"},"source":["def predict_image(img_path, model):\r\n","  img = np.array(Image.open(img_path)) #Открываем картинку с входного пути\r\n","  \r\n","  actual_height = img.shape[0]         #Записываем высоту оригинальной картинки\r\n","  actual_width = img.shape[1]          #Записываем шырину оригинальной картинки\r\n","\r\n","  width = 512                          #Ширина которая будет подаваться в НС\r\n","  height = 768                         #Высота которая будет подаваться в НС\r\n","  input_img = cv.resize(img, (width, height), interpolation = cv.INTER_LANCZOS4) #Делаем Reshape для входа в НС\r\n","  actual_img = cv.resize(img, (width * 2, height * 2), interpolation = cv.INTER_LANCZOS4) #Делаем Reshape для настоящей картинки\r\n","  input_img = np.expand_dims(input_img, axis = 0) #Добавляем ось для НС\r\n","  pred_image = model.predict(input_img/255).reshape((height, width, num_classes)) #Получаем результат с НС и делаем обратный предикт\r\n","  \r\n","  pred = index2color(pred_image, actual_img, color = (255, 255, 255), final_mode = True).astype(np.uint8) #Обрабатываем данные с сегментации\r\n","  pred = cv.resize(pred, (actual_width, actual_height), interpolation = cv.INTER_LANCZOS4) #Делаем reshape обратно\r\n","\r\n","  pred = Image.fromarray(pred) #Переводим с numpy массива в картинку\r\n","  return pred #Возвращаем картинку"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CiVAjjLHvgge"},"source":["model_best = get_model_from_file()\r\n","predict_image(directory + 'orig/дог200.jpg', model = model_best)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggupiqchvnkU"},"source":["for i, filename in enumerate(os.listdir(directory + 'orig/')):\r\n","  pred = predict_image(directory + f'orig/{filename}', model = model_best)\r\n","  plt.figure(figsize = (20, 20))\r\n","  print(str(i) + '_' * 50)\r\n","  plt.imshow(np.array(pred))\r\n","  plt.show()"],"execution_count":null,"outputs":[]}]}